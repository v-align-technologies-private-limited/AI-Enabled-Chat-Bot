{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5ab237-369f-40d3-b973-be2b3732684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    table_name       column_name          data_type  character_maximum_length\n",
      "0   milestones      project_name  character varying                     255.0\n",
      "1   milestones    milestone_name  character varying                     255.0\n",
      "2   milestones        owner_name  character varying                     255.0\n",
      "3   milestones  milestone_status  character varying                     100.0\n",
      "4   milestones              flag  character varying                     100.0\n",
      "..         ...               ...                ...                       ...\n",
      "61       users        user_email               text                       NaN\n",
      "62       users              role               text                       NaN\n",
      "63       users           profile               text                       NaN\n",
      "64       users            status               text                       NaN\n",
      "65       users      active_users               text                       NaN\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Basavaraj\\AppData\\Local\\Temp\\ipykernel_18036\\67750690.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted batch for project_name in milestones\n",
      "Upserted batch for project_name in milestones\n",
      "Upserted batch for project_name in milestones\n",
      "Upserted batch for project_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for milestone_name in milestones\n",
      "Upserted batch for owner_name in milestones\n",
      "Upserted batch for milestone_status in milestones\n",
      "Upserted batch for flag in milestones\n",
      "Upserted batch for milestone_completion_mode in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for milestone_id_string in milestones\n",
      "Upserted batch for project_id_string in milestones\n",
      "Upserted batch for project_id_string in milestones\n",
      "Upserted batch for project_id_string in milestones\n",
      "Upserted batch for project_id_string in milestones\n",
      "Upserted batch for tags in milestones\n",
      "Upserted batch for status in milestones\n",
      "Upserted batch for commitment_type in milestones\n",
      "Upserted batch for skill in milestones\n",
      "Upserted batch for application in milestones\n",
      "Upserted batch for if_others in milestones\n",
      "Upserted batch for project_name in projects\n",
      "Upserted batch for project_name in projects\n",
      "Upserted batch for project_name in projects\n",
      "Upserted batch for project_name in projects\n",
      "Upserted batch for owner in projects\n",
      "Upserted batch for status in projects\n",
      "Upserted batch for delivery_team in projects\n",
      "Upserted batch for client_project_id in projects\n",
      "Upserted batch for client_project_id in projects\n",
      "Upserted batch for client_project_id in projects\n",
      "Upserted batch for client_project_id in projects\n",
      "Upserted batch for bug_prefix in projects\n",
      "Upserted batch for bug_prefix in projects\n",
      "Upserted batch for bug_prefix in projects\n",
      "Upserted batch for bug_prefix in projects\n",
      "Upserted batch for task_prefix in projects\n",
      "Upserted batch for task_prefix in projects\n",
      "Upserted batch for task_prefix in projects\n",
      "Upserted batch for task_prefix in projects\n",
      "Upserted batch for key in projects\n",
      "Upserted batch for key in projects\n",
      "Upserted batch for key in projects\n",
      "Upserted batch for key in projects\n",
      "Upserted batch for billing_method in projects\n",
      "Upserted batch for project_type in projects\n",
      "Upserted batch for country in projects\n",
      "Upserted batch for required_apps in projects\n",
      "Upserted batch for crm_deal_id in projects\n",
      "Upserted batch for crm_deal_id in projects\n",
      "Upserted batch for crm_deal_id in projects\n",
      "Upserted batch for account_name in projects\n",
      "Upserted batch for account_name in projects\n",
      "Upserted batch for delivery_master in projects\n",
      "Upserted batch for developers in projects\n",
      "Upserted batch for timeline_status in projects\n",
      "Upserted batch for health_status in projects\n",
      "Upserted batch for tags in projects\n",
      "Upserted batch for previous_delivery_owner in projects\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for task_name in tasks\n",
      "Upserted batch for owner in tasks\n",
      "Upserted batch for owner in tasks\n",
      "Upserted batch for priority in tasks\n",
      "Upserted batch for status in tasks\n",
      "Upserted batch for completion_percentage in tasks\n",
      "Upserted batch for created_by in tasks\n",
      "Upserted batch for project_name in tasks\n",
      "Upserted batch for milestone_name in tasks\n",
      "Upserted batch for milestone_name in tasks\n",
      "Upserted batch for tasklist_name in tasks\n",
      "Upserted batch for tasklist_name in tasks\n",
      "Upserted batch for created_by_id in tasks\n",
      "Upserted batch for owner_ids in tasks\n",
      "Upserted batch for owner_ids in tasks\n",
      "Upserted batch for task_delay_time in tasks\n",
      "Upserted batch for task_delay_time in tasks\n",
      "Upserted batch for task_completion_mode in tasks\n",
      "Upserted batch for actual_time_taken in tasks\n",
      "Upserted batch for actual_time_taken in tasks\n",
      "Upserted batch for time_spent_so_far in tasks\n",
      "Upserted batch for time_spent_so_far in tasks\n",
      "Upserted batch for duration_unit in tasks\n",
      "Upserted batch for clarity_level in tasks\n",
      "Upserted batch for sprint in tasks\n",
      "Upserted batch for billing_type in tasks\n",
      "Upserted batch for product_skill in tasks\n",
      "Upserted batch for sprint_ff_sf in tasks\n",
      "Upserted batch for open_closed in tasks\n",
      "Upserted batch for allocated_unallocated in tasks\n",
      "Upserted batch for days_completed_on in tasks\n",
      "Upserted batch for sprint_new in tasks\n",
      "Upserted batch for qc_owner in tasks\n",
      "Upserted batch for user_name in users\n",
      "Upserted batch for user_name in users\n",
      "Upserted batch for user_email in users\n",
      "Upserted batch for user_email in users\n",
      "Upserted batch for role in users\n",
      "Upserted batch for profile in users\n",
      "Upserted batch for status in users\n",
      "Upserted batch for active_users in users\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "# PostgreSQL database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432\n",
    "\n",
    "# Pinecone details\n",
    "pinecone_api_key = \"9fbe58e4-9e72-4023-90eb-ba8d022916b5\"\n",
    "index_name = \"jagoai\"\n",
    "BATCH_SIZE = 200  # Adjust the batch size if necessary\n",
    "\n",
    "# Function to connect to PostgreSQL database\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Fetch schema with column names and data types\n",
    "def fetch_schema_with_data_types(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type, character_maximum_length\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "          AND (data_type = 'character varying' OR data_type IN ('text', 'varchar'))\n",
    "          AND table_name IN ('projects', 'milestones', 'tasks', 'users')\n",
    "        ORDER BY table_name;\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        print(schema_df)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema with data types: {e}\")\n",
    "        raise\n",
    "\n",
    "# Fetch unique values from each column for specified tables\n",
    "def fetch_unique_values(conn, table_name, column_name):\n",
    "    try:\n",
    "        query = f\"SELECT DISTINCT {column_name} FROM {table_name}\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df[column_name].dropna().astype(str).tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching unique values for {column_name} in {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load Hugging Face model for embeddings\n",
    "def load_huggingface_model():\n",
    "    model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    embedding_model = SentenceTransformer(model_name)\n",
    "    return embedding_model\n",
    "\n",
    "# Generate embeddings for unique values and store them in a dictionary\n",
    "def generate_embeddings(embedding_model, unique_values_dict):\n",
    "    embeddings_dict = {}\n",
    "    for table_name, columns in unique_values_dict.items():\n",
    "        embeddings_dict[table_name] = {}\n",
    "        for column_name, unique_values in columns.items():\n",
    "            if unique_values:  # Check if there are any unique values\n",
    "                try:\n",
    "                    embeddings = embedding_model.encode(unique_values)\n",
    "                    embeddings_dict[table_name][column_name] = {\n",
    "                        \"unique_values\": unique_values,\n",
    "                        \"embeddings\": embeddings\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating embeddings for {column_name} in {table_name}: {e}\")\n",
    "                    embeddings_dict[table_name][column_name] = {\n",
    "                        \"unique_values\": unique_values,\n",
    "                        \"embeddings\": []\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"No unique values found for {column_name} in {table_name}. Skipping embeddings.\")\n",
    "                embeddings_dict[table_name][column_name] = {\n",
    "                    \"unique_values\": [],\n",
    "                    \"embeddings\": []\n",
    "                }\n",
    "    return embeddings_dict\n",
    "\n",
    "# Initialize Pinecone index\n",
    "def initialize_pinecone():\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "    index = pc.Index(index_name)\n",
    "    return index\n",
    "\n",
    "# Batch the embeddings for upserts\n",
    "def batch_embeddings(upsert_data, batch_size):\n",
    "    for i in range(0, len(upsert_data), batch_size):\n",
    "        yield upsert_data[i:i + batch_size]\n",
    "\n",
    "# Upsert embeddings into Pinecone with metadata for each table (namespace)\n",
    "def upsert_embeddings(index, embeddings_dict):\n",
    "    for table_name, columns in embeddings_dict.items():\n",
    "        for column_name, data in columns.items():\n",
    "            upsert_data = []\n",
    "            for i, embedding in enumerate(data['embeddings']):\n",
    "                unique_value = data['unique_values'][i]\n",
    "                vector_id = f\"{table_name}_{column_name}_{i}\"\n",
    "                metadata = {\n",
    "                    \"table_name\": table_name,\n",
    "                    \"column_name\": column_name,\n",
    "                    \"unique_value\": unique_value\n",
    "                }\n",
    "\n",
    "                upsert_data.append({\n",
    "                    \"id\": vector_id,\n",
    "                    \"values\": embedding.tolist(),\n",
    "                    \"metadata\": metadata\n",
    "                })\n",
    "\n",
    "            # Batch the upsert to avoid exceeding size limits\n",
    "            for batch in batch_embeddings(upsert_data, BATCH_SIZE):\n",
    "                index.upsert(vectors=batch)\n",
    "                print(f\"Upserted batch for {column_name} in {table_name}\")\n",
    "\n",
    "# Main function to execute the entire process\n",
    "def main():\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db()\n",
    "\n",
    "    # Fetch the schema and unique values for relevant columns\n",
    "    schema_df = fetch_schema_with_data_types(conn)\n",
    "    unique_values_dict = {}\n",
    "    for _, row in schema_df.iterrows():\n",
    "        table_name = row['table_name']\n",
    "        column_name = row['column_name']\n",
    "        if table_name not in unique_values_dict:\n",
    "            unique_values_dict[table_name] = {}\n",
    "        unique_values_dict[table_name][column_name] = fetch_unique_values(conn, table_name, column_name)\n",
    "\n",
    "    # Load the Hugging Face model for embeddings\n",
    "    embedding_model = load_huggingface_model()\n",
    "\n",
    "    # Generate embeddings for unique values\n",
    "    embeddings_dict = generate_embeddings(embedding_model, unique_values_dict)\n",
    "\n",
    "    # Initialize Pinecone and upsert embeddings\n",
    "    index = initialize_pinecone()\n",
    "    upsert_embeddings(index, embeddings_dict)\n",
    "\n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "\n",
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d613c00-796d-40c8-a367-6e0abc27a34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
