{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485dc141-65e5-49cd-a037-d883015a2887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pinecone\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "OPENAI_API_KEY = \"\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501e00e2-87d7-4c46-811a-042014f560df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"9fbe58e4-9e72-4023-90eb-ba8d022916b5\"  # Replace with your Pinecone API key\n",
    "INDEX_NAME = \"smart-desk\"  # Replace with your Pinecone index name\n",
    "NAMESPACE = []  # Replace with your namespace\n",
    "columnnames={}\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a652b50-1645-47b0-a386-ad4040558a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_model():\n",
    "    return SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff7a885-0715-4ea3-94cd-0f14622dc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pinecone():\n",
    "    from pinecone import Pinecone, ServerlessSpec\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    if INDEX_NAME not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=768,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    "        )\n",
    "    return pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4698dd97-eab3-4070-b113-f0e853ca80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec28cfa-33cb-4124-9c3a-d9f81d4d2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_schema(schema_df):\n",
    "    def clean_column_name(name):\n",
    "        return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "    schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "    return schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef07d8e6-be94-4745-b44d-75dde324e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_with_openai(user_input, processed_schema_df):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "    # Refined prompt to ensure OpenAI extracts table names, column names, and their values\n",
    "    prompt = f\"\"\"\n",
    "    ## Database Schema Context:\n",
    "    The following represents the columns and their respective tables available in the database:\n",
    "    {schema_json}\n",
    "\n",
    "    ## User Input:\n",
    "    The user has provided the following input: \"{user_input}\"\n",
    "\n",
    "    ## Task:\n",
    "    Extract the relevant features, values, and table names from the user input based on the schema. These features might include project names, owners, dates, statuses, etc., along with their corresponding table names.\n",
    "\n",
    "    ## Instructions:\n",
    "    - Return a JSON dictionary that includes the table names as keys, and within each table, include the fields and their values extracted from the user input.\n",
    "    - Omit any fields or tables where the value is empty or null.\n",
    "    - Format the output as a JSON object with keys only for tables and fields that have values.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        extracted_features = response.choices[0].text.strip()\n",
    "        return extracted_features\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error with OpenAI: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6ac8e0-b280-46f3-8db6-8e9f85dcf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_extracted_features(extracted_features):\n",
    "    try:\n",
    "        # Remove the \"## Solution:\" part and any other non-JSON text\n",
    "        json_match = re.search(r'\\{.*\\}', extracted_features, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            # Extract the JSON part from the matched result\n",
    "            cleaned_features = json_match.group(0)\n",
    "\n",
    "            # Convert JSON string to a Python dictionary\n",
    "            feature_dict = json.loads(cleaned_features)\n",
    "\n",
    "            # Clean feature dictionary and feature list to remove nulls and empty values\n",
    "            cleaned_feature_dict, feature_list = clean_extracted_features(feature_dict)\n",
    "\n",
    "            # Return cleaned JSON and feature list\n",
    "            return json.dumps(cleaned_feature_dict, indent=4), feature_list\n",
    "        else:\n",
    "            return None, []\n",
    "    except (json.JSONDecodeError, ValueError) as e:\n",
    "        print(f\"Error parsing features: {e}\")\n",
    "        return None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea4a17b-0989-4f3d-bb9f-966b6c3aa434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extracted_features(feature_dict):\n",
    "    # Remove any keys with None or empty values\n",
    "    cleaned_feature_dict = {k: v for k, v in feature_dict.items() if v}\n",
    "    # Extract the non-null values into a list\n",
    "    feature_list = list(cleaned_feature_dict.values())\n",
    "    return cleaned_feature_dict, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588b3d1b-cdc8-453c-b442-d889538faf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nmaespace(extracted_dict):\n",
    "    global NAMESPACE,columnnames\n",
    "    for key in extracted_dict.keys():\n",
    "        NAMESPACE.append(key)\n",
    "        columnnames[key]= extracted_dict[key]\n",
    "    #columnnames=columnnames.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f312d401-a95c-4fa4-9660-0fdb3841e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_cols=[]\n",
    "def query_pinecone_and_augment_input(user_input, entities, namespace, columns):\n",
    "    global searched_cols\n",
    "    embedding_model = load_huggingface_model()\n",
    "    pinecone_index = initialize_pinecone()\n",
    "    augmented_input = user_input\n",
    "    pinecone_data = {}\n",
    "\n",
    "    # Function to flatten the nested dictionary\n",
    "    def flatten_dict(d, parent_key=''):\n",
    "        items = []\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                items.extend(flatten_dict(v, new_key).items())\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "        return dict(items)\n",
    "\n",
    "    # Flatten the entities dictionary\n",
    "    flat_entities = flatten_dict(entities)\n",
    "    \n",
    "    #print(\"Table:\", namespace)\n",
    "    for column_name in columns:\n",
    "        if column_name not in searched_cols:\n",
    "            #print(\"Column name:\", column_name)\n",
    "            searched_cols.append(column_name)\n",
    "\n",
    "            # Obtain the entity value corresponding to the current column\n",
    "            entity_value = entities[namespace].get(column_name, None)\n",
    "            if not entity_value:\n",
    "                continue  # Skip to the next column if no value is found\n",
    "\n",
    "            # Generate the query embedding for the entity value\n",
    "            query_embedding = embedding_model.encode([entity_value])[0]\n",
    "            query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "\n",
    "            try:\n",
    "                result = pinecone_index.query(\n",
    "                    namespace=namespace,\n",
    "                    vector=query_embedding.tolist(),\n",
    "                    filter={\n",
    "                        \"column_name\": {\"$eq\": column_name}\n",
    "                    },\n",
    "                    top_k=3,\n",
    "                    include_values=True,\n",
    "                    include_metadata=True\n",
    "                )\n",
    "                \n",
    "                matches = result.get('matches', [])\n",
    "                #print(\"matches:\",matches)\n",
    "                if matches:\n",
    "                    unique_values = [match['metadata'].get('unique_value') for match in matches if 'metadata' in match]\n",
    "                    if unique_values:\n",
    "                        pinecone_data[column_name] = unique_values\n",
    "                        if len(unique_values) > 1:\n",
    "                            print(f\"Multiple matches found for '{entity_value}':\")\n",
    "                            for idx, unique_value in enumerate(unique_values):\n",
    "                                print(f\"{idx + 1}: {unique_value}\")\n",
    "                            while True:\n",
    "                                selection = input(f\"Please select the most relevant option for '{entity_value}' (1-{len(unique_values)}): \")\n",
    "                                try:\n",
    "                                    selected_value = unique_values[int(selection) - 1]\n",
    "                                    augmented_input = augmented_input.replace(entity_value, selected_value)\n",
    "                                    break\n",
    "                                except (IndexError, ValueError):\n",
    "                                    print(\"Invalid selection. Please choose a valid option.\")\n",
    "                        else:\n",
    "                            augmented_input = augmented_input.replace(entity_value, unique_values[0])\n",
    "                else:\n",
    "                    print(f\"No matches found for {entity_value} in Pinecone.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error querying Pinecone: {str(e)}\")\n",
    "                return f\"Error querying Pinecone: {str(e)}\", {}\n",
    "                \n",
    "    return augmented_input, pinecone_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866cbc44-0905-4844-a74b-2d25003739c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(user_input):\n",
    "    global NAMESPACE,columnnames\n",
    "    # Connect to DB and fetch schema\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema(conn)\n",
    "    #processed_schema_df = process_schema(schema_df)\n",
    "    # Extract features from user input using OpenAI\n",
    "    extracted_features = extract_features_with_openai(user_input, schema_df)\n",
    "    # Process the extracted features and clean them\n",
    "    cleaned_json, feature_list = process_extracted_features(extracted_features)\n",
    "    #print(\"Cleaned json:\",cleaned_json)\n",
    "    #print(\"Feature list:\",feature_list)\n",
    "    cleaned_feature_dict = json.loads(cleaned_json)\n",
    "    cleaned_extracted_features, feature_list = clean_extracted_features(cleaned_feature_dict)  # Rename the variable here\n",
    "    extract_namespace = extract_nmaespace(cleaned_extracted_features)\n",
    "    for key,val in cleaned_feature_dict.items():\n",
    "        x=list(val.keys())\n",
    "        #print(x)\n",
    "        #print(\"For values:\",user_input, cleaned_feature_dict, key,x)\n",
    "        augmented_input, pinecone_data=query_pinecone_and_augment_input(user_input, cleaned_feature_dict, key,x)\n",
    "        print(augmented_input)\n",
    "        #print(pinecone_data)\n",
    "        return augmented_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e98db-9c99-483d-a48f-7f459f1d6abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  give me the list of Completed tasks of a project IIFL Samasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11480\\3423304458.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Explaination: To fetch the list of completed tasks for the project \"IIFL Samasta,\" we need to join the `tasks` and `projects` tables based on the `project_id`. We'll filter the tasks to include only those with a status indicating completion. Assuming that the completed tasks have a status of 'Completed' (you may adjust this based on your actual status values), the SQL query will look like this\n",
      "Generated SQL Query: SELECT t.*\n",
      "FROM tasks t\n",
      "JOIN projects p ON t.project_id = p.project_id\n",
      "WHERE p.project_name = 'IIFL Samasta'\n",
      "AND t.status LIKE 'Completed';\n"
     ]
    }
   ],
   "source": [
    "# Function to connect to PostgreSQL database\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Fetch schema with column names and data types\n",
    "def fetch_schema_with_data_types(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema with data types: {e}\")\n",
    "        raise\n",
    "\n",
    "# Format schema as a string for the prompt\n",
    "def format_schema(schema_df):\n",
    "    schema_str = \"\"\n",
    "    grouped = schema_df.groupby('table_name')\n",
    "    for table_name, group in grouped:\n",
    "        columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "        schema_str += f\"{table_name}: {columns}\\n\"\n",
    "    return schema_str\n",
    "#Fetch query explainer text\n",
    "def fetch_query_explaination(text):\n",
    "    match = re.search(r'(.*?):', text)\n",
    "\n",
    "    # Print the result if found\n",
    "    if match:\n",
    "        return (match.group(1))\n",
    "\n",
    "# Function to generate SQL query using GPT-4o-mini\n",
    "def generate_sql_query(schema_str, user_input):\n",
    "    prompt = f\"\"\"\n",
    "    The database contains the following schema:\n",
    "    {schema_str}\n",
    "\n",
    "    Based on this schema and the user request:\n",
    "    \"{user_input}\"\n",
    " \n",
    "    Generate an optimized SQL query that meets the user's intent.\n",
    "    The query should be efficient and use the correct table and column names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call GPT-4o-mini-2024-07-18 model using chat completion API\n",
    "    #rephrased the prompt\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries, ensuring the use of appropriate operators like LIKE or expressions in sql queries like '% %' for  matches if needed. Accurately map user input to the relevant tables and columns in the database based on the provided schema, using the LIKE operator for partial matches where necessary. Handle data type mismatches explicitly by casting to the appropriate type when required, ensuring correct query execution. Additionally, Manage variations in user input, such as case sensitivity or small spelling differences, using flexible matching techniques to generate precise and reliable SQL queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,  # Reduced token limit for completion\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Extract SQL query from the response\n",
    "    sql_response = response.choices[0].message.content\n",
    "    # Find and clean the SQL query part\n",
    "    start = sql_response.find(\"```sql\") + 6\n",
    "    end = sql_response.find(\"```\", start)\n",
    "    sql_query = sql_response\n",
    "    \n",
    "\n",
    "    return sql_query,sql_response\n",
    "\n",
    "# Extract generated SQL Query\n",
    "def extract_sql_query(response):\n",
    "    start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "    end = response.find(\"```\", start)\n",
    "    sql_query = response[start:end].strip()\n",
    "    return sql_query\n",
    "\n",
    "# Initialize OpenAI Chat model\n",
    "openai_model = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    model_name=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "#Generate Response\n",
    "# Update the generate_response function\n",
    "def generate_response(user_query, sql_result):\n",
    "    # Prepare the prompt for GPT-4 to generate the natural language response\n",
    "    prompt = f\"User query: \\\"{user_query}\\\"\\nSQL result: {sql_result}\\nGenerate a natural language response from the result:\"\n",
    "    \n",
    "    # Call the OpenAI Chat API\n",
    "    response = openai.chat.completions.create(\n",
    "      model=\"gpt-4o-mini-2024-07-18\",\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      max_tokens=500,\n",
    "      temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Make sure to replace the completion calls elsewhere in the code\n",
    "\n",
    "    \n",
    "# Create a ChatPromptTemplate with the knowledge base included\n",
    "template = \"\"\"\n",
    "## Knowledge Base:\n",
    "{knowledge_base}\n",
    "\n",
    "## Database Schema:\n",
    "{database_schema}\n",
    "\n",
    "## Question:\n",
    "{question}\n",
    "\n",
    "## Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def get_answer_from_chatbot(question, database_schema):\n",
    "    try:\n",
    "        prompt = prompt_template.format(\n",
    "            knowledge_base=\"\",\n",
    "            database_schema=database_schema,\n",
    "            question=question\n",
    "        )\n",
    "        response = openai_model.invoke(input=prompt)\n",
    "        parsed_response = response.content.strip() if hasattr(response, 'content') else \"No response content found.\"\n",
    "        return parsed_response\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response from OpenAI: {str(e)}\"\n",
    "        \n",
    "# Function to execute the SQL query and print the results\n",
    "def execute_sql_query(conn, sql_query):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "            results = cursor.fetchall()\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n",
    "        \n",
    "# Determine if user query is related to database or general knowledge\n",
    "def determine_query_type(user_query, schema_df, threshold=75):\n",
    "    user_query_lower = user_query.lower()\n",
    "    \n",
    "    # Extract unique table and column names from the schema and convert to lowercase\n",
    "    table_names = schema_df['table_name'].str.lower().unique()\n",
    "    column_names = schema_df['column_name'].str.lower().unique()\n",
    "    \n",
    "    # Function to check fuzzy match\n",
    "    def is_fuzzy_match(query, options, threshold):\n",
    "        for option in options:\n",
    "            if fuzz.partial_ratio(query, option) >= threshold:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Check if user query matches any table or column name\n",
    "    if is_fuzzy_match(user_query_lower, table_names, threshold) or \\\n",
    "       is_fuzzy_match(user_query_lower, column_names, threshold):\n",
    "        return \"database\"\n",
    "    \n",
    "    return \"knowledge\"\n",
    "\n",
    "# Main function to handle user queries\n",
    "def process_user_query(user_input):\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema_with_data_types(conn)\n",
    "    processed_schema_str = format_schema(schema_df)\n",
    "    query_type = determine_query_type(user_input, schema_df)\n",
    "\n",
    "    if query_type == \"database\":\n",
    "        sql_query,sql_response = generate_sql_query(processed_schema_str, user_input)\n",
    "        sql_query=extract_sql_query(sql_query)\n",
    "        explain_text=fetch_query_explaination(sql_response)\n",
    "        print(\"Query Explaination:\",explain_text)\n",
    "        print(\"Generated SQL Query:\", sql_query)\n",
    "\n",
    "        \n",
    "        # Execute the generated SQL query\n",
    "        results = execute_sql_query(conn, sql_query)\n",
    "        rows=results\n",
    "        # print(\"Row:\",rows)\n",
    "        if len(rows)!=0:\n",
    "            resp=generate_response(user_input,rows)\n",
    "            result=resp+\"\\n\"+explain_text\n",
    "            return result\n",
    "        else:\n",
    "            return \"I'm sorry, but I'm unable to provide results. Could you please clarify your query so I can assist you better?\"\n",
    "        \n",
    "        conn.close()\n",
    "    \n",
    "    else:\n",
    "        # For non-database related queries, respond using the chatbot\n",
    "        return get_answer_from_chatbot(user_input, processed_schema_str)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input(\"Enter your query: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            break\n",
    "        response = process_user_query(user_input)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2c18d-1dac-4672-8cab-4e51b1a24699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28abcdbe-d1bf-4a13-bf60-3bcc079b0134",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71afab-f2bb-4905-8acd-8f5113542fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
