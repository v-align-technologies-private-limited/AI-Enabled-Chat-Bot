{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f157cc-08ce-46e9-a0a5-916d91f2f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13856\\1248652289.py:72: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features from OpenAI:\n",
      "- project_name: \n",
      "   - owner: Mohammed\n",
      "   - date: \n",
      "   - status: \n",
      "   - project_id: \n",
      "   - start_date: \n",
      "   - created_time: \n",
      "   - delivery_team: \n",
      "   - project_efforts: \n",
      "   - status: \n",
      "   - end_date: \n",
      "   - project_name: \n",
      "   - owner_name: \n",
      "   - user_name: Mohammed\n",
      "   - role: \n",
      "   - project_name: \n",
      "   - start_date: \n",
      "   - end_date: \n",
      "   - status: \n",
      "   - project_efforts: \n",
      "   - created_time: \n",
      "   - delivery_team: \n",
      "   - owner: Mohammed\n",
      "\n",
      "Parsed Feature List:\n",
      "[]\n",
      "No features to query.\n",
      "\n",
      "Augmented User Input:\n",
      "Show all projects owned by Mohammed\n",
      "\n",
      "Generated SQL Query:\n",
      "SELECT projectid, projectname, ownername      FROM projects      WHERE ownername LIKE '%Mohammed%'\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "OPENAI_API_KEY = \"\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Pinecone Initialization\n",
    "PINECONE_API_KEY = \"9fbe58e4-9e72-4023-90eb-ba8d022916b5\"\n",
    "INDEX_NAME = \"jagoai\"\n",
    "\n",
    "# Initialize HuggingFace Embeddings model\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert user input to vector\n",
    "def text_to_vector(text):\n",
    "    return embedder.embed_query(text)\n",
    "\n",
    "# Initialize Pinecone client\n",
    "def initialize_pinecone():\n",
    "    # Create Pinecone instance\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "    # Check if index exists and create if it doesn't\n",
    "    if INDEX_NAME not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=embedder.embedding_dim,  # Assuming your embedding dimension\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "        )\n",
    "    \n",
    "    return pc.Index(INDEX_NAME)\n",
    "\n",
    "# Database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432\n",
    "\n",
    "# Function to connect to PostgreSQL database\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to fetch schema from PostgreSQL database\n",
    "def fetch_schema(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to process schema: remove special characters and convert to lowercase\n",
    "def process_schema(schema_df):\n",
    "    def clean_column_name(name):\n",
    "        return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "    schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "    return schema_df\n",
    "\n",
    "# LangChain PromptTemplate to augment user input\n",
    "def augment_user_input(user_input, closest_match):\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"closest_match\"],\n",
    "        template=\"\"\"\n",
    "        User provided input: \"{user_input}\".\n",
    "        Pinecone retrieved the closest match: \"{closest_match}\".\n",
    "\n",
    "        Update the user input by replacing the original input with the closest match.\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.7)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    augmented_input = chain.run(user_input=user_input, closest_match=closest_match)\n",
    "    return augmented_input.strip()\n",
    "\n",
    "# Function to extract features (like project name, owner, etc.) using OpenAI's LLM\n",
    "def extract_features_with_openai(user_input, processed_schema_df):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "    # Construct prompt for OpenAI LLM\n",
    "    prompt = f\"\"\"\n",
    "    ## Database Schema Context\n",
    "    {schema_json}\n",
    "\n",
    "    ## User Input\n",
    "    User has provided the following input: '{user_input}'.\n",
    "\n",
    "    ## Instructions\n",
    "    Based on the given user input and the database schema provided above, identify all features or values the user is trying to express. These features could include project names, owners, dates, statuses, or any other information that matches the schema. Extract them and return as a structured list.Also if you do not find feture or values than return them as empty string.\n",
    "\n",
    "    Provide the output in the following format:\n",
    "    - project_name: \n",
    "    - owner: \n",
    "    - date: \n",
    "    - status:\n",
    "    - [Any other relevant column values based on schema]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        extracted_features = response.choices[0].text.strip()\n",
    "        return extracted_features\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error with OpenAI: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to parse and store extracted features into a list\n",
    "def parse_extracted_features(extracted_features):\n",
    "    feature_list = []\n",
    "    \n",
    "    # Using regex to extract key-value pairs\n",
    "    for line in extracted_features.splitlines():\n",
    "        match = re.match(r\"-\\s(\\w+):\\s(.+)\", line)\n",
    "        if match:\n",
    "            key = match.group(1).strip()\n",
    "            value = match.group(2).strip()\n",
    "            # Only add to the feature list if the value is not empty\n",
    "            if value and value.lower() not in {\"none\", \"not specified\", \" \",\"N/A\"}:\n",
    "                feature_list.append(value)\n",
    "    \n",
    "    return feature_list\n",
    "\n",
    "# Function to query Pinecone using the extracted features\n",
    "def query_pinecone(index, feature_list):\n",
    "    if not feature_list:\n",
    "        print(\"No features to query.\")\n",
    "        return []\n",
    "\n",
    "    closest_matches = []\n",
    "    for feature in feature_list:\n",
    "        vector = text_to_vector(feature)\n",
    "        try:\n",
    "            response = index.query(\n",
    "                vector=vector,\n",
    "                top_k=1,\n",
    "                include_values=True,\n",
    "                include_metadata=True\n",
    "            )\n",
    "\n",
    "            # Process and collect matching records\n",
    "            if 'matches' in response and response['matches']:\n",
    "                match = response['matches'][0]\n",
    "                match_id = match.get('id', 'N/A')\n",
    "                score = match.get('score', 'N/A')\n",
    "                metadata = match.get('metadata', 'No metadata')\n",
    "                values = match.get('values', 'No values')\n",
    "\n",
    "                closest_match = metadata.get('value', 'No match found')\n",
    "                print(f\"Feature: {feature} - Closest Match: {closest_match}\")\n",
    "                closest_matches.append((feature, closest_match))\n",
    "            else:\n",
    "                print(f\"No matches found for feature: {feature}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred querying Pinecone for feature '{feature}':\", e)\n",
    "\n",
    "    return closest_matches\n",
    "\n",
    "# Function to generate SQL query using OpenAI API and LangChain\n",
    "def generate_sql_query(user_input, processed_schema_df, entities):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    ## Database Schema Context\n",
    "    {schema_json}\n",
    "\n",
    "    ## User Input\n",
    "    User input: \"{user_input}\"\n",
    "    Extracted entities: {entities}\n",
    "\n",
    "    ## Instructions\n",
    "    Based on the user input and the database schema, generate an SQL query that correctly maps to the database tables and columns.\n",
    "    Use the LIKE operator where necessary for partial matches.\n",
    "    \"\"\"\n",
    "\n",
    "    context = prompt_template.format(\n",
    "        schema_json=schema_json,\n",
    "        user_input=user_input,\n",
    "        entities=entities\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=context,\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        generated_query = response.choices[0].text.strip()\n",
    "        return generated_query\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error generating SQL query: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to clean the generated SQL query\n",
    "def clean_sql_query(sql_query):\n",
    "    sql_query_cleaned = re.sub(r'##.*\\n', '', sql_query)\n",
    "    sql_query_cleaned = sql_query_cleaned.replace(\"\\n\", \" \").strip()\n",
    "    return sql_query_cleaned\n",
    "\n",
    "# Main function to process user input, fetch schema, extract features, and query Pinecone\n",
    "def process_user_input_and_query_pinecone(user_input):\n",
    "    # Connect to DB and fetch schema\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema(conn)\n",
    "    processed_schema_df = process_schema(schema_df)\n",
    "\n",
    "    # Extract features from user input using OpenAI's LLM\n",
    "    extracted_features = extract_features_with_openai(user_input, processed_schema_df)\n",
    "    \n",
    "    print(\"Extracted Features from OpenAI:\")\n",
    "    print(extracted_features)\n",
    "\n",
    "    # Parse extracted features into a list\n",
    "    feature_list = parse_extracted_features(extracted_features)\n",
    "    \n",
    "    print(\"\\nParsed Feature List:\")\n",
    "    print(feature_list)\n",
    "\n",
    "    # Initialize Pinecone and query based on the feature list\n",
    "    index = initialize_pinecone()\n",
    "    closest_matches = query_pinecone(index, feature_list)\n",
    "\n",
    "    # Augment user input with closest matches\n",
    "    for feature, closest_match in closest_matches:\n",
    "        user_input = augment_user_input(user_input, closest_match)\n",
    "    \n",
    "    print(\"\\nAugmented User Input:\")\n",
    "    print(user_input)\n",
    "\n",
    "    # Generate SQL query using augmented input\n",
    "    generated_query = generate_sql_query(user_input, processed_schema_df, closest_matches)\n",
    "    cleaned_query = clean_sql_query(generated_query)\n",
    "    \n",
    "    print(\"\\nGenerated SQL Query:\")\n",
    "    print(cleaned_query)\n",
    "\n",
    "    return cleaned_query\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"Show all projects owned by Mohammed\"\n",
    "    process_user_input_and_query_pinecone(user_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
