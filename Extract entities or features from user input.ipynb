{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cff8b0-5985-4d81-8efc-e6944c449ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  what is the status of a project IIFL Samasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15224\\1923470864.py:40: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features from OpenAI:\n",
      "## Output:\n",
      "    {\n",
      "        \"project_name\": \"IIFL Samasta\",\n",
      "        \"status\": \"in progress\"\n",
      "    }\n",
      "Error parsing features: unexpected indent (<string>, line 2)\n",
      "\n",
      "Parsed Feature Dictionary:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "OPENAI_API_KEY = \"\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432\n",
    "\n",
    "# Function to connect to PostgreSQL database\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to fetch schema from PostgreSQL database\n",
    "def fetch_schema(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to process schema: remove special characters and convert to lowercase\n",
    "def process_schema(schema_df):\n",
    "    def clean_column_name(name):\n",
    "        return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "    schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "    return schema_df\n",
    "\n",
    "# Function to extract features (like project name, owner, etc.) using OpenAI's LLM\n",
    "def extract_features_with_openai(user_input, processed_schema_df):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "    # Refined prompt to ensure OpenAI only returns valid matches\n",
    "    prompt = f\"\"\"\n",
    "    ## Database Schema Context:\n",
    "    The following represents the columns available in the database:\n",
    "    {schema_json}\n",
    "\n",
    "    ## User Input:\n",
    "    The user has provided the following input: \"{user_input}\"\n",
    "\n",
    "    ## Task:\n",
    "    Extract the relevant features or values from the user input based on the schema. These features might include project names, owners, dates, statuses, etc. \n",
    "\n",
    "    ## Instructions:\n",
    "    - Return the fields that have valid values based on the user input in a JSON dictionary format.\n",
    "    - Omit any fields where the value is empty or null.\n",
    "    - Format the output as a JSON object with keys only for fields that have values.\n",
    "    - Example:\n",
    "      {{\n",
    "        \"project_name\": \"Some Project\",\n",
    "        \"owner\": \"Some Owner\"\n",
    "      }}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        extracted_features = response.choices[0].text.strip()\n",
    "        return extracted_features\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error with OpenAI: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to parse and store extracted features into a dictionary\n",
    "def parse_extracted_features(extracted_features):\n",
    "    try:\n",
    "        feature_dict = eval(extracted_features)  # Convert string representation to dictionary\n",
    "        # Ensure values are valid and not placeholders\n",
    "        cleaned_dict = {k: v for k, v in feature_dict.items() if v and v.lower() not in {'no relevant value found', 'none', 'n/a', 'not specified'}}\n",
    "        return cleaned_dict\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error parsing features: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Main function to process user input and extract entities\n",
    "def process_user_input(user_input):\n",
    "    # Connect to DB and fetch schema\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema(conn)\n",
    "    processed_schema_df = process_schema(schema_df)\n",
    "\n",
    "    # Extract features from user input using OpenAI's LLM\n",
    "    extracted_features = extract_features_with_openai(user_input, processed_schema_df)\n",
    "    \n",
    "    # Print the extracted features\n",
    "    print(\"Extracted Features from OpenAI:\")\n",
    "    print(extracted_features)\n",
    "\n",
    "    # Parse extracted features into a dictionary\n",
    "    feature_dict = parse_extracted_features(extracted_features)\n",
    "    \n",
    "    # Print the parsed feature dictionary\n",
    "    print(\"\\nParsed Feature Dictionary:\")\n",
    "    print(feature_dict)\n",
    "\n",
    "# Get user input\n",
    "user_input = input(\"Enter your query: \")\n",
    "\n",
    "# Process user input and extract entities\n",
    "process_user_input(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5d44fb-c2bc-4807-b8be-23c2a3719fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import json\n",
    "\n",
    "# # Initialize OpenAI API key\n",
    "# OPENAI_API_KEY = \"sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S\"\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# # Database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Function to fetch schema from PostgreSQL database\n",
    "# def fetch_schema(conn):\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Function to process schema: remove special characters and convert to lowercase\n",
    "# def process_schema(schema_df):\n",
    "#     def clean_column_name(name):\n",
    "#         return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "#     schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "#     return schema_df\n",
    "\n",
    "# # Function to extract features (like project name, owner, etc.) using OpenAI's LLM\n",
    "# def extract_features_with_openai(user_input, processed_schema_df):\n",
    "#     schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "#     # Refined prompt to ensure OpenAI only returns valid matches\n",
    "#     prompt = f\"\"\"\n",
    "#     ## Database Schema Context:\n",
    "#     The following represents the columns available in the database:\n",
    "#     {schema_json}\n",
    "\n",
    "#     ## User Input:\n",
    "#     The user has provided the following input: \"{user_input}\"\n",
    "\n",
    "#     ## Task:\n",
    "#     Extract the relevant features or values from the user input based on the schema. These features might include project names, owners, dates, statuses, etc. \n",
    "\n",
    "#     ## Instructions:\n",
    "#     - Return the fields that have valid values based on the user input in a JSON dictionary format.\n",
    "#     - Omit any fields where the value is empty or null.\n",
    "#     - Format the output as a JSON object with keys only for fields that have values.\n",
    "#     - Example:\n",
    "#       {{\n",
    "#         \"project_name\": \"Some Project\",\n",
    "#         \"owner\": \"Some Owner\"\n",
    "#       }}\n",
    "#     \"\"\"\n",
    "\n",
    "#     try:\n",
    "#         response = openai.completions.create(\n",
    "#             model=\"gpt-3.5-turbo-instruct\",\n",
    "#             prompt=prompt,\n",
    "#             max_tokens=500,\n",
    "#             temperature=0.5\n",
    "#         )\n",
    "#         extracted_features = response.choices[0].text.strip()\n",
    "#         print(\"Raw Extracted Features:\")\n",
    "#         print(extracted_features)  # Print the raw output for debugging\n",
    "#         return extracted_features\n",
    "#     except openai.OpenAIError as e:\n",
    "#         print(f\"Error with OpenAI: {e}\")\n",
    "#         raise\n",
    "      \n",
    "# # Main function to process user input and extract entities\n",
    "# def process_user_input(user_input):\n",
    "#     # Connect to DB and fetch schema\n",
    "#     conn = connect_to_db()\n",
    "#     schema_df = fetch_schema(conn)\n",
    "#     processed_schema_df = process_schema(schema_df)\n",
    "\n",
    "#     # Extract features from user input using OpenAI's LLM\n",
    "#     extracted_features = extract_features_with_openai(user_input, processed_schema_df)\n",
    "    \n",
    "\n",
    "# # Get user input\n",
    "# user_input = input(\"Enter your query: \")\n",
    "\n",
    "# # Process user input and extract entities\n",
    "# process_user_input(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8193ae-7018-47d0-8644-ef0176315726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extract entities or features from user input\n",
    "# import openai\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import json\n",
    "\n",
    "# # Initialize OpenAI API key\n",
    "# OPENAI_API_KEY = \"sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S\"\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# # Database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Function to fetch schema from PostgreSQL database\n",
    "# def fetch_schema(conn):\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Function to process schema: remove special characters and convert to lowercase\n",
    "# def process_schema(schema_df):\n",
    "#     def clean_column_name(name):\n",
    "#         return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "#     schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "#     return schema_df\n",
    "\n",
    "# # Function to extract features (like project name, owner, etc.) using OpenAI's LLM\n",
    "# def extract_features_with_openai(user_input, processed_schema_df):\n",
    "#     schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "#     # Refined prompt to ensure OpenAI only returns valid matches\n",
    "#     prompt = f\"\"\"\n",
    "#     ## Database Schema Context:\n",
    "#     The following represents the columns available in the database:\n",
    "#     {schema_json}\n",
    "\n",
    "#     ## User Input:\n",
    "#     The user has provided the following input: \"{user_input}\"\n",
    "\n",
    "#     ## Task:\n",
    "#     Extract the relevant features or values from the user input based on the schema. These features might include project names, owners, dates, statuses, etc. \n",
    "\n",
    "#     ## Instructions:\n",
    "#     - Return the fields that have valid values based on the user input in a JSON dictionary format.\n",
    "#     - Omit any fields where the value is empty or null.\n",
    "#     - Format the output as a JSON object with keys only for fields that have values.\n",
    "#     \"\"\"\n",
    "\n",
    "#     try:\n",
    "#         response = openai.completions.create(\n",
    "#             model=\"gpt-3.5-turbo-instruct\",\n",
    "#             prompt=prompt,\n",
    "#             max_tokens=500,\n",
    "#             temperature=0.5\n",
    "#         )\n",
    "#         extracted_features = response.choices[0].text.strip()\n",
    "#         return extracted_features\n",
    "#     except openai.OpenAIError as e:\n",
    "#         print(f\"Error with OpenAI: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Function to remove null, None, empty values from JSON and list\n",
    "# def clean_extracted_features(feature_dict):\n",
    "#     # Remove any keys with None or empty values\n",
    "#     cleaned_feature_dict = {k: v for k, v in feature_dict.items() if v}\n",
    "#     # Extract the non-null values into a list\n",
    "#     feature_list = list(cleaned_feature_dict.values())\n",
    "#     return cleaned_feature_dict, feature_list\n",
    "\n",
    "# # Function to parse and process extracted features\n",
    "# def process_extracted_features(extracted_features):\n",
    "#     try:\n",
    "#         # Remove the \"## Solution:\" part and any other non-JSON text\n",
    "#         json_match = re.search(r'\\{.*\\}', extracted_features, re.DOTALL)\n",
    "        \n",
    "#         if json_match:\n",
    "#             # Extract the JSON part from the matched result\n",
    "#             cleaned_features = json_match.group(0)\n",
    "\n",
    "#             # Convert JSON string to a Python dictionary\n",
    "#             feature_dict = json.loads(cleaned_features)\n",
    "\n",
    "#             # Clean feature dictionary and feature list to remove nulls and empty values\n",
    "#             cleaned_feature_dict, feature_list = clean_extracted_features(feature_dict)\n",
    "\n",
    "#             # Return cleaned JSON and feature list\n",
    "#             return json.dumps(cleaned_feature_dict, indent=4), feature_list\n",
    "#         else:\n",
    "#             return None, []\n",
    "#     except (json.JSONDecodeError, ValueError) as e:\n",
    "#         print(f\"Error parsing features: {e}\")\n",
    "#         return None, []\n",
    "\n",
    "# # Main function to process user input and extract entities\n",
    "# def process_user_input(user_input):\n",
    "#     # Connect to DB and fetch schema\n",
    "#     conn = connect_to_db()\n",
    "#     schema_df = fetch_schema(conn)\n",
    "#     processed_schema_df = process_schema(schema_df)\n",
    "\n",
    "#     # Extract features from user input using OpenAI's LLM\n",
    "#     extracted_features = extract_features_with_openai(user_input, processed_schema_df)\n",
    "\n",
    "#     # Process the extracted features and clean them\n",
    "#     cleaned_json, feature_list = process_extracted_features(extracted_features)\n",
    "\n",
    "#     # Output cleaned JSON and feature list\n",
    "#     if cleaned_json:\n",
    "#         print(\"Cleaned Extracted JSON Features:\")\n",
    "#         print(cleaned_json)\n",
    "    \n",
    "#     print(\"Feature List:\")\n",
    "#     print(feature_list)\n",
    "\n",
    "# # Get user input\n",
    "# user_input = input(\"Enter your query: \")\n",
    "\n",
    "# # Process user input and extract entities\n",
    "# process_user_input(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3b62d-a847-41f1-b143-936b17298332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
