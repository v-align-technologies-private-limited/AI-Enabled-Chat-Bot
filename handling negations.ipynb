{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fcb4a0-476b-4a63-8c78-3c6012280b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from openai_manager import *\n",
    "from initial_config import *\n",
    "from db_manager import *\n",
    "\n",
    "class Pinecone_manager:\n",
    "    def __init__(self, schema_df):\n",
    "        self.NAMESPACE = []  # Replace with your namespace\n",
    "        self.columnnames = {}\n",
    "        self.searched_cols = []\n",
    "        self.searched_tables = []\n",
    "        self.augmented_input = ''\n",
    "        self.intermediate_input=''\n",
    "        self.schema_df = schema_df\n",
    "        self.extracted_Features = None\n",
    "        self.cleaned_feature_dict = None\n",
    "        self.tokenizer= None\n",
    "        self.pinecone_index = None\n",
    "        self.selection={}\n",
    "        self.selection_required=False\n",
    "        self.ic=Initialize_config()\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.NAMESPACE = []  # Replace with your namespace\n",
    "        self.columnnames = {}\n",
    "        self.searched_cols = []\n",
    "        self.searched_tables = []\n",
    "        self.augmented_input = ''\n",
    "        self.intermediate_input=''\n",
    "        self.selection={}\n",
    "        self.selection_required=False\n",
    "\n",
    "    def process_user_input(self, user_input):\n",
    "        self.extracted_Features = OpenAI_manager.extract_features_with_openai(OpenAI_manager, user_input, self.schema_df)\n",
    "        #print(self.extracted_Features)\n",
    "\n",
    "    def process_extracted_features(self):\n",
    "        def clean_extracted_features(feature_dict):\n",
    "            print(feature_dict)\n",
    "            # Remove any keys with None or empty values\n",
    "            cleaned_feature_dict = {k: v for k, v in feature_dict.items() if v not in [None, '', [], {}, 'none', 'null', 'n/a', 'not specified']}\n",
    "            # Extract the non-null values into a list\n",
    "            feature_list = list(cleaned_feature_dict.values())\n",
    "            return cleaned_feature_dict, feature_list\n",
    "\n",
    "        try:\n",
    "            # Remove the \"## Solution:\" part and any other non-JSON text\n",
    "            json_match = re.search(r'\\{.*\\}', self.extracted_Features, re.DOTALL)\n",
    "            \n",
    "            if json_match:\n",
    "                # Extract the JSON part from the matched result\n",
    "                cleaned_features = json_match.group(0)\n",
    "\n",
    "                # Convert JSON string to a Python dictionary\n",
    "                feature_dict = json.loads(cleaned_features)\n",
    "\n",
    "                # Clean feature dictionary and feature list to remove nulls and empty values\n",
    "                self.cleaned_feature_dict, feature_list = clean_extracted_features(feature_dict)\n",
    "\n",
    "                # Return cleaned JSON and feature list\n",
    "                return json.dumps(self.cleaned_feature_dict, indent=4), feature_list\n",
    "            else:\n",
    "                return None, []\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"Error parsing features: {e}\")\n",
    "            return None, []\n",
    "\n",
    "    def extract_namespace(self):\n",
    "        for key in self.extracted_dict.keys():\n",
    "            self.NAMESPACE.append(key)\n",
    "            self.columnnames[key] = extracted_dict[key]\n",
    "    #reframe the input with selected values\n",
    "    def call_query_pinecone1(self, user_input, p_i, data):\n",
    "        print(\"pineconedata\", data)\n",
    "        for x in data.keys():\n",
    "            selected=str(data[x])\n",
    "            user_input=user_input.replace(x,selected)\n",
    "        self.augmented_input=user_input\n",
    "        print(\"augumented_input\", self.augmented_input)\n",
    "        self.selection_required=False\n",
    "        \n",
    "    #check if any multiple values for each entity found in vectorDB\n",
    "    def call_query_pinecone(self, user_input, p_i):\n",
    "        res=''\n",
    "        self.pinecone_index = p_i\n",
    "        for key, val in self.cleaned_feature_dict.items():\n",
    "            columns = list(val.keys())\n",
    "            tables=list(val.values())\n",
    "            print(columns)\n",
    "            if self.augmented_input == '':\n",
    "                res = self.query_pinecone_and_augment_input(user_input, key, columns,tables)\n",
    "            else:\n",
    "                res = self.query_pinecone_and_augment_input(self.augmented_input, key, columns,tables)\n",
    "        print(\"augumentedinput\",res)\n",
    "        self.clear_all()\n",
    "        return res\n",
    "    def create_prompt(self,query):\n",
    "        \"\"\"\n",
    "        Creates a structured prompt to handle negation and context.\n",
    "        \"\"\"\n",
    "        if \"not\" in query.lower():\n",
    "            return f\"Input query: {query}. Focus on the meaning and negation.\"\n",
    "        return f\"Input query: {query}. Interpret the query accurately.\"\n",
    "    \n",
    "\n",
    "    def query_pinecone_and_augment_input(self, user_input, namespace, columns,tables):\n",
    "        openai.api_key=self.ic.return_key()\n",
    "        self.augmented_input = user_input\n",
    "\n",
    "        def flatten_dict(d, parent_key=''):\n",
    "            items = []\n",
    "            for k, v in d.items():\n",
    "                new_key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "                if isinstance(v, dict):\n",
    "                    items.extend(flatten_dict(v, new_key).items())\n",
    "                else:\n",
    "                    items.append((new_key, v))\n",
    "            return dict(items)\n",
    "\n",
    "        flat_entities = flatten_dict(self.cleaned_feature_dict)\n",
    "        #print(flat_entities)\n",
    "        for column_name,table_name in zip(columns,tables):\n",
    "            print(column_name)\n",
    "            \n",
    "            if column_name not in self.searched_cols or table_name not in self.searched_tables:\n",
    "                self.searched_cols.append(column_name)\n",
    "                self.searched_tables.append(table_name)\n",
    "\n",
    "                # Obtain the entity value corresponding to the current column\n",
    "                entity_value = self.cleaned_feature_dict[namespace].get(column_name, None)\n",
    "                #print(entity_value)\n",
    "                if not entity_value:\n",
    "                    print(True)\n",
    "                    continue  # Skip to the next column if no value is found\n",
    "                #entity_value=self.create_prompt(entity_value)\n",
    "\n",
    "                # Generate the query embedding for the entity value\n",
    "                response = openai.embeddings.create(\n",
    "                    model=\"text-embedding-3-large\",  # Correct embedding model\n",
    "                    input=\"Input query: {entity_value}. Focus on the meaning and negation.\"  # Input must be a list\n",
    "                )\n",
    "                embedding = response.data[0].embedding\n",
    "\n",
    "                try:\n",
    "                    result = self.pinecone_index.query(\n",
    "                        namespace=namespace,\n",
    "                        vector=embedding,\n",
    "                        filter={\"column_name\": {\"$eq\": column_name}},\n",
    "                        top_k=3,\n",
    "                        include_values=True,\n",
    "                        include_metadata=True\n",
    "                    )\n",
    "\n",
    "                    matches = result.get('matches', [])\n",
    "                    #print(matches)\n",
    "                    if matches:\n",
    "                        get_match=[]\n",
    "                        # Sort matches by score in descending order\n",
    "                        matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "                        # Check if multiple matches have a significant score difference\n",
    "                        best_match = matches[0]\n",
    "                        print(\"match1:\",matches[0]['metadata'].get('unique_value', entity_value))\n",
    "                        print(\"match2:\",matches[1]['metadata'].get('unique_value', entity_value))\n",
    "                        print(\"match3:\",matches[2]['metadata'].get('unique_value', entity_value))\n",
    "                        print(\"Best match:\",matches[0]['metadata'].get('unique_value', entity_value))\n",
    "                        best_score = best_match['score']\n",
    "                        print(\"Best Score:\",best_score)\n",
    "                        selection_required = False\n",
    "                        selected_match = best_match['metadata'].get('unique_value', entity_value)\n",
    "\n",
    "                        # Check if any other match has a score difference < 0.1\n",
    "                        for match in matches[1:]:\n",
    "                            print(\"MAtch score:\",match['score'])\n",
    "                            score_diff = best_score - match['score']\n",
    "                            if score_diff < 0.07:\n",
    "                                selection_required = True\n",
    "                                break\n",
    "                            else:\n",
    "                                continue\n",
    "                                \n",
    "                        if selection_required:\n",
    "                            # Record the values for multiple values to select among the matches\n",
    "                            print(f\"Multiple matches found with significant score difference for '{entity_value}'. Please select:\")\n",
    "                            for i, match in enumerate(matches):\n",
    "                                get_match.append(match['metadata'].get('unique_value', entity_value))\n",
    "                            self.selection[entity_value]=get_match\n",
    "                            self.selection_required=True\n",
    "                        else:\n",
    "                            best_match_for_1_entity = matches[0]['metadata'].get('unique_value', entity_value)\n",
    "                            #print('best_match_for_1_entity', best_match_for_1_entity)\n",
    "                            self.augmented_input = self.augmented_input.replace(entity_value, best_match_for_1_entity)\n",
    "\n",
    "                        \n",
    "                    else:\n",
    "                        print(f\"No matches found for {entity_value} in Pinecone.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error querying Pinecone: {str(e)}\")\n",
    "            else:\n",
    "                print(\"Column already searched\")\n",
    "        if self.selection_required==True:\n",
    "            \n",
    "            print(\"Selection dict:\",self.selection)\n",
    "            print(\"Recent:\",self.intermediate_input)\n",
    "            return {\"selection\": self.selection}\n",
    "        else:\n",
    "            return self.augmented_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2acbc0e-0d5d-48b0-a417-045105d9a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI-Enabled-Chat-Bot-staging\\schema_manager.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  self.schema_df=pd.read_sql(self.query, self.conn)\n"
     ]
    }
   ],
   "source": [
    "from schema_manager import *\n",
    "DB=DB_Manager()\n",
    "openai_manager=OpenAI_manager()\n",
    "p=Initialize_config()\n",
    "p.assign_pinecone_index()\n",
    "p.process_openAI_model()\n",
    "p.set_prompt_template()\n",
    "db_name=\"zoho_projects_data_v2_backup\"\n",
    "conn = DB.connect(DATABASE_DB = f\"{db_name}\")\n",
    "schema='public'\n",
    "query = f\"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = '{schema}'\n",
    "        \"\"\"\n",
    "schema_manager=Schema_manager(conn,query,schema)\n",
    "schema_manager.fetch_schema_with_data_types()\n",
    "schema_manager.format_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be103d60-3fee-4f4a-99d5-9674ad1e26f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'projects_zoho_projects_': {'status': 'not completed'}, 'milestones_zoho_projects_': {'status': 'delayed'}}\n",
      "['status']\n",
      "status\n",
      "match1: Requirement Gathering\n",
      "match2: Blocked\n",
      "match3: Cancelled\n",
      "Best match: Requirement Gathering\n",
      "Best Score: 0.161346883\n",
      "MAtch score: 0.150252745\n",
      "Multiple matches found with significant score difference for 'not completed'. Please select:\n",
      "Selection dict: {'not completed': ['Requirement Gathering', 'Blocked', 'Cancelled']}\n",
      "Recent: \n",
      "['status']\n",
      "status\n",
      "match1: Overdue\n",
      "match2: Completed\n",
      "match3: Archived\n",
      "Best match: Overdue\n",
      "Best Score: 0.121680744\n",
      "MAtch score: 0.121019356\n",
      "Multiple matches found with significant score difference for 'delayed'. Please select:\n",
      "Selection dict: {'not completed': ['Requirement Gathering', 'Blocked', 'Cancelled'], 'delayed': ['Overdue', 'Completed', 'Archived']}\n",
      "Recent: \n",
      "augumentedinput {'selection': {'not completed': ['Requirement Gathering', 'Blocked', 'Cancelled'], 'delayed': ['Overdue', 'Completed', 'Archived']}}\n",
      "{'selection': {'not completed': ['Requirement Gathering', 'Blocked', 'Cancelled'], 'delayed': ['Overdue', 'Completed', 'Archived']}}\n"
     ]
    }
   ],
   "source": [
    "user_input=\"give me the count all not completed projects which have delayed milestone\"\n",
    "pine_cone=Pinecone_manager(schema_manager.schema_df)\n",
    "pine_cone.process_user_input(user_input)\n",
    "_, feature_list=pine_cone.process_extracted_features()\n",
    "res1=pine_cone.call_query_pinecone(user_input,p.pinecone_index)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956d5fb-58a6-4912-9937-a29e6a19d36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
