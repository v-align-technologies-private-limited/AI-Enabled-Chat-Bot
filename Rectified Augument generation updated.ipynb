{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485dc141-65e5-49cd-a037-d883015a2887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash\\anaconda3\\envs\\py310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Prakash\\anaconda3\\envs\\py310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash\\anaconda3\\envs\\py310\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pinecone\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "# Initialize OpenAI API key\n",
    "OPENAI_API_KEY = \"\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# Database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501e00e2-87d7-4c46-811a-042014f560df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"9fbe58e4-9e72-4023-90eb-ba8d022916b5\"  # Replace with your Pinecone API key\n",
    "INDEX_NAME = \"smart-desk\"  # Replace with your Pinecone index name\n",
    "# Initialize OpenAI Chat model\n",
    "openai_model = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    model_name=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "# Make sure to replace the completion calls elsewhere in the code   \n",
    "# Create a ChatPromptTemplate with the knowledge base included\n",
    "template = \"\"\"\n",
    "## Knowledge Base:\n",
    "{knowledge_base}\n",
    "\n",
    "## Database Schema:\n",
    "{database_schema}\n",
    "\n",
    "## Question:\n",
    "{question}\n",
    "\n",
    "## Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "NAMESPACE = []  # Replace with your namespace\n",
    "columnnames={}\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "searched_cols=[]\n",
    "augmented_input=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a652b50-1645-47b0-a386-ad4040558a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_model():\n",
    "    return SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff7a885-0715-4ea3-94cd-0f14622dc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pinecone():\n",
    "    from pinecone import Pinecone, ServerlessSpec\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    if INDEX_NAME not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=768,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    "        )\n",
    "    return pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4698dd97-eab3-4070-b113-f0e853ca80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9e87f8-9753-473b-87d7-f5558fba53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_schema(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        # print(schema_df)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec28cfa-33cb-4124-9c3a-d9f81d4d2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_schema(schema_df):\n",
    "    def clean_column_name(name):\n",
    "        return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "    schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "    return schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef07d8e6-be94-4745-b44d-75dde324e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_with_openai(user_input, processed_schema_df):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "    \n",
    "    # Refined prompt to ensure OpenAI extracts table names, column names, and their values\n",
    "    prompt = f\"\"\"\n",
    "    ## Database Schema Context:\n",
    "    The following represents the columns and their respective tables available in the database:\n",
    "    {schema_json}\n",
    "\n",
    "    ## User Input:\n",
    "    The user has provided the following input: \"{user_input}\"\n",
    "\n",
    "    ## Task:\n",
    "    Extract the relevant features, values, and table names from the user input based on the schema. These features might include project names, owners, dates, statuses, etc., along with their corresponding table names.\n",
    "\n",
    "    ## Instructions:\n",
    "    - Return a JSON dictionary that includes the table names as keys, and within each table, include the fields and their values extracted from the user input.\n",
    "    - Omit any fields or tables where the value is empty or null.\n",
    "    - Format the output as a JSON object with keys only for tables and fields that have values.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        extracted_features = response.choices[0].text.strip()\n",
    "        return extracted_features\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error with OpenAI: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6ac8e0-b280-46f3-8db6-8e9f85dcf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_extracted_features(extracted_features):\n",
    "    try:\n",
    "        # Remove the \"## Solution:\" part and any other non-JSON text\n",
    "        json_match = re.search(r'\\{.*\\}', extracted_features, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            # Extract the JSON part from the matched result\n",
    "            cleaned_features = json_match.group(0)\n",
    "\n",
    "            # Convert JSON string to a Python dictionary\n",
    "            feature_dict = json.loads(cleaned_features)\n",
    "\n",
    "            # Clean feature dictionary and feature list to remove nulls and empty values\n",
    "            cleaned_feature_dict, feature_list = clean_extracted_features(feature_dict)\n",
    "\n",
    "            # Return cleaned JSON and feature list\n",
    "            return json.dumps(cleaned_feature_dict, indent=4), feature_list\n",
    "        else:\n",
    "            return None, []\n",
    "    except (json.JSONDecodeError, ValueError) as e:\n",
    "        print(f\"Error parsing features: {e}\")\n",
    "        return None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea4a17b-0989-4f3d-bb9f-966b6c3aa434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extracted_features(feature_dict):\n",
    "    # Remove any keys with None or empty values\n",
    "    cleaned_feature_dict = {k: v for k, v in feature_dict.items() if v}\n",
    "    # Extract the non-null values into a list\n",
    "    feature_list = list(cleaned_feature_dict.values())\n",
    "    return cleaned_feature_dict, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7977c533-2aa9-4d3d-ae2d-7a35cc9b591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nmaespace(extracted_dict):\n",
    "    global NAMESPACE,columnnames,augmented_input\n",
    "    for key in extracted_dict.keys():\n",
    "        NAMESPACE.append(key)\n",
    "        columnnames[key]= extracted_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f312d401-a95c-4fa4-9660-0fdb3841e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone_and_augment_input(user_input, entities, namespace, columns):\n",
    "    global searched_cols\n",
    "    embedding_model = load_huggingface_model()\n",
    "    pinecone_index = initialize_pinecone()\n",
    "    augmented_input = user_input\n",
    "    pinecone_data = {}\n",
    "\n",
    "    # Function to flatten the nested dictionary\n",
    "    def flatten_dict(d, parent_key=''):\n",
    "        items = []\n",
    "        for k, v in d.items():\n",
    "            new_key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "            if isinstance(v, dict):\n",
    "                items.extend(flatten_dict(v, new_key).items())\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "        return dict(items)\n",
    "\n",
    "    # Flatten the entities dictionary\n",
    "    flat_entities = flatten_dict(entities)\n",
    "    \n",
    "    #print(\"Table:\", namespace)\n",
    "    for column_name in columns:\n",
    "        if column_name not in searched_cols:\n",
    "            #print(\"Column name:\", column_name)\n",
    "            searched_cols.append(column_name)\n",
    "\n",
    "            # Obtain the entity value corresponding to the current column\n",
    "            entity_value = entities[namespace].get(column_name, None)\n",
    "            if not entity_value:\n",
    "                continue  # Skip to the next column if no value is found\n",
    "\n",
    "            # Generate the query embedding for the entity value\n",
    "            query_embedding = embedding_model.encode([entity_value])[0]\n",
    "            query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "\n",
    "            try:\n",
    "                result = pinecone_index.query(\n",
    "                    namespace=namespace,\n",
    "                    vector=query_embedding.tolist(),\n",
    "                    filter={\n",
    "                        \"column_name\": {\"$eq\": column_name}\n",
    "                    },\n",
    "                    top_k=3,\n",
    "                    include_values=True,\n",
    "                    include_metadata=True\n",
    "                )\n",
    "                \n",
    "                matches = result.get('matches', [])\n",
    "                #print(\"matches:\",matches)\n",
    "                if matches:\n",
    "                    unique_values = [match['metadata'].get('unique_value') for match in matches if 'metadata' in match]\n",
    "                    if unique_values:\n",
    "                        pinecone_data[column_name] = unique_values\n",
    "                        if len(unique_values) > 1:\n",
    "                            print(f\"Multiple matches found for '{entity_value}':\")\n",
    "                            for idx, unique_value in enumerate(unique_values):\n",
    "                                print(f\"{idx + 1}: {unique_value}\")\n",
    "                            while True:\n",
    "                                selection = input(f\"Please select the most relevant option for '{entity_value}' (1-{len(unique_values)}): \")\n",
    "                                try:\n",
    "                                    selected_value = unique_values[int(selection) - 1]\n",
    "                                    augmented_input = augmented_input.replace(entity_value, selected_value)\n",
    "                                    break\n",
    "                                except (IndexError, ValueError):\n",
    "                                    print(\"Invalid selection. Please choose a valid option.\")\n",
    "                        else:\n",
    "                            augmented_input = augmented_input.replace(entity_value, unique_values[0])\n",
    "                else:\n",
    "                    print(f\"No matches found for {entity_value} in Pinecone.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error querying Pinecone: {str(e)}\")\n",
    "                return f\"Error querying Pinecone: {str(e)}\", {}\n",
    "                \n",
    "    return augmented_input, pinecone_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4db8bcf-5187-485c-83a7-a7787abb3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_values():\n",
    "    global NAMESPACE,columnnames,searched_cols\n",
    "    NAMESPACE.clear()\n",
    "    columnnames.clear()\n",
    "    searched_cols.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90b2c18d-1dac-4672-8cab-4e51b1a24699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(user_input):\n",
    "    clear_values()\n",
    "    aug_result=''\n",
    "    # Connect to DB and fetch schema\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema(conn)\n",
    "    #processed_schema_df = process_schema(schema_df)\n",
    "    # Extract features from user input using OpenAI\n",
    "    extracted_features = extract_features_with_openai(user_input, schema_df)\n",
    "    # Process the extracted features and clean them\n",
    "    cleaned_json, feature_list = process_extracted_features(extracted_features)\n",
    "    #print(\"Cleaned json:\",cleaned_json)\n",
    "    #print(\"Feature list:\",feature_list)\n",
    "    cleaned_feature_dict = json.loads(cleaned_json)\n",
    "    cleaned_extracted_features, feature_list = clean_extracted_features(cleaned_feature_dict)  # Rename the variable here\n",
    "    extract_namespace = extract_nmaespace(cleaned_extracted_features)\n",
    "    for key,val in cleaned_feature_dict.items():\n",
    "        x=list(val.keys())\n",
    "        #print(x)\n",
    "        #print(\"For values:\",user_input, cleaned_feature_dict, key,x)\n",
    "        if aug_result=='':\n",
    "            aug_result, pinecone_data=query_pinecone_and_augment_input(user_input, cleaned_feature_dict, key,x)\n",
    "        else:\n",
    "            aug_result, pinecone_data=query_pinecone_and_augment_input(aug_result, cleaned_feature_dict, key,x)\n",
    "    return (aug_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9382071d-0b5c-4a6a-9c07-8645937fdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch schema with column names and data types\n",
    "def fetch_schema_with_data_types(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema with data types: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3bfe7ce-9b97-4f36-aa89-b5ed9c328afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Format schema as a string for the prompt\n",
    "def format_schema(schema_df):\n",
    "    schema_str = \"\"\n",
    "    grouped = schema_df.groupby('table_name')\n",
    "    for table_name, group in grouped:\n",
    "        columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "        schema_str += f\"{table_name}: {columns}\\n\"\n",
    "    return schema_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e98cbb74-3f67-4e09-9f9c-9fe1d0e0057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Fetch query explainer text\n",
    "def fetch_query_explaination(text):\n",
    "    match = re.search(r'(.*?):', text)\n",
    "\n",
    "    # Print the result if found\n",
    "    if match:\n",
    "        return (match.group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5df58db6-7783-456b-a0b6-0d7bb7f65b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate SQL query using GPT-4o-mini\n",
    "def generate_sql_query(schema_str, user_input):\n",
    "    prompt = f\"\"\"\n",
    "    The database contains the following schema:\n",
    "    {schema_str}\n",
    "\n",
    "    Based on this schema and the user request:\n",
    "    \"{user_input}\"\n",
    " \n",
    "    Generate an optimized SQL query that meets the user's intent.\n",
    "    The query should be efficient and use the correct table and column names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call GPT-4o-mini-2024-07-18 model using chat completion API\n",
    "    #rephrased the prompt\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries, ensuring the use of appropriate operators like LIKE or expressions in sql queries like '% %' for  matches if needed. Accurately map user input to the relevant tables and columns in the database based on the provided schema, using the LIKE operator for partial matches where necessary. Handle data type mismatches explicitly by casting to the appropriate type when required, ensuring correct query execution. Additionally, Manage variations in user input, such as case sensitivity or small spelling differences, using flexible matching techniques to generate precise and reliable SQL queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,  # Reduced token limit for completion\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Extract SQL query from the response\n",
    "    sql_response = response.choices[0].message.content\n",
    "    # Find and clean the SQL query part\n",
    "    start = sql_response.find(\"```sql\") + 6\n",
    "    end = sql_response.find(\"```\", start)\n",
    "    sql_query = sql_response\n",
    "    \n",
    "\n",
    "    return sql_query,sql_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fc286e9-d7b2-4445-bf1c-3d1465da4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract generated SQL Query\n",
    "def extract_sql_query(response):\n",
    "    start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "    end = response.find(\"```\", start)\n",
    "    sql_query = response[start:end].strip()\n",
    "    return sql_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d30ae66-6207-4ebc-9b8f-0086d5820ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate Response\n",
    "# Update the generate_response function\n",
    "def generate_response(user_query, sql_result):\n",
    "    # Prepare the prompt for GPT-4 to generate the natural language response\n",
    "    prompt = f\"User query: \\\"{user_query}\\\"\\nSQL result: {sql_result}\\nGenerate a natural language response from the result:\"\n",
    "    \n",
    "    # Call the OpenAI Chat API\n",
    "    response = openai.chat.completions.create(\n",
    "      model=\"gpt-4o-mini-2024-07-18\",\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      max_tokens=500,\n",
    "      temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e55269ff-bdb2-4c28-81bb-0c529f1d5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_answer_from_chatbot(question, database_schema):\n",
    "    try:\n",
    "        prompt = prompt_template.format(\n",
    "            knowledge_base=\"\",\n",
    "            database_schema=database_schema,\n",
    "            question=question\n",
    "        )\n",
    "        response = openai_model.invoke(input=prompt)\n",
    "        parsed_response = response.content.strip() if hasattr(response, 'content') else \"No response content found.\"\n",
    "        return parsed_response\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response from OpenAI: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0cf6018-8324-48ad-8212-bfd464177fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Function to execute the SQL query and print the results\n",
    "def execute_sql_query(conn, sql_query):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "            results = cursor.fetchall()\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aecb4ac0-6baf-4007-b4e8-2291a543281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Determine if user query is related to database or general knowledge\n",
    "def determine_query_type(user_query, schema_df, threshold=75):\n",
    "    user_query_lower = user_query.lower()\n",
    "    \n",
    "    # Extract unique table and column names from the schema and convert to lowercase\n",
    "    table_names = schema_df['table_name'].str.lower().unique()\n",
    "    column_names = schema_df['column_name'].str.lower().unique()\n",
    "    \n",
    "    # Function to check fuzzy match\n",
    "    def is_fuzzy_match(query, options, threshold):\n",
    "        for option in options:\n",
    "            if fuzz.partial_ratio(query, option) >= threshold:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Check if user query matches any table or column name\n",
    "    if is_fuzzy_match(user_query_lower, table_names, threshold) or \\\n",
    "       is_fuzzy_match(user_query_lower, column_names, threshold):\n",
    "        return \"database\"\n",
    "    \n",
    "    return \"knowledge\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9fa180f-f767-4225-80aa-92006cb8a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def contains_date_related_text(user_input):\n",
    "    # Current year and month for comparison\n",
    "    current_year = datetime.now().year\n",
    "    current_month = datetime.now().strftime(\"%B\")\n",
    "    \n",
    "    # Patterns to match date, month, year, and relative terms\n",
    "    date_pattern = r'\\b(\\d{1,2}[-/\\.]\\d{1,2}[-/\\.]\\d{2,4}|\\d{4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,2})\\b'\n",
    "    month_pattern = r'\\b(January|February|March|April|May|June|July|August|September|October|November|December|' \\\n",
    "                    r'Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\b'\n",
    "    year_pattern = r'\\b(19|20)\\d{2}\\b'\n",
    "    time_pattern = r'\\b\\d+\\s*(or\\s*(more|fewer|less))?\\s*(days?|weeks?|months?|years?)\\b'\n",
    "    relative_terms_pattern = r'\\b(this month|this year|last month|last year|next month|next year)\\b'\n",
    "    \n",
    "    # Find matches\n",
    "    if (re.search(date_pattern, user_input) or \n",
    "        re.search(month_pattern, user_input, re.IGNORECASE) or \n",
    "        re.search(year_pattern, user_input) or \n",
    "        re.search(time_pattern, user_input) or\n",
    "        re.search(relative_terms_pattern, user_input, re.IGNORECASE)):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "072c4ce2-6ca1-456a-888e-e864358083a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def named_entity_recognition(text):\n",
    "    doc = nlp(text)\n",
    "    # Check for entities that are either PERSON, ORG, or GPE\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ in (\"PERSON\", \"ORG\", \"GPE\"):\n",
    "            return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35622b34-1b50-4ad3-a625-54c3a67d8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_entity_present(schema_entities,user_text):\n",
    "    user_text_lower = user_text.lower()\n",
    "    for entity in schema_entities:\n",
    "        if entity.lower() in user_text_lower:\n",
    "            return True  \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87f6251d-a81a-45aa-81b5-6e86b8797146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle user queries\n",
    "def process_user_query(user_input):\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema_with_data_types(conn)\n",
    "    processed_schema_str = format_schema(schema_df)\n",
    "    query_type = determine_query_type(user_input, schema_df)\n",
    "    if query_type == \"database\":\n",
    "        is_entity=is_entity_present(schema_df['column_name'].tolist(),user_input)\n",
    "        if contains_date_related_text(user_input):\n",
    "            if named_entity_recognition(user_input):\n",
    "                if is_enity:\n",
    "                    aug_input=process_user_input(user_input)\n",
    "                else:\n",
    "                    aug_input=user_input\n",
    "            else:\n",
    "                aug_input=user_input\n",
    "        else:\n",
    "            aug_input=process_user_input(user_input)\n",
    "        sql_query,sql_response = generate_sql_query(processed_schema_str, aug_input)\n",
    "        sql_query=extract_sql_query(sql_query)\n",
    "        explain_text=fetch_query_explaination(sql_response)\n",
    "        #print(\"Query Explaination:\",explain_text)\n",
    "        print(\"Generated SQL Query:\", sql_query)\n",
    "\n",
    "        \n",
    "        # Execute the generated SQL query\n",
    "        results = execute_sql_query(conn, sql_query)\n",
    "        rows=results\n",
    "        print(\"Row:\",rows)\n",
    "        if len(rows)!=0:\n",
    "            resp=generate_response(aug_input,rows)\n",
    "            result=resp+\"\\n\"+explain_text\n",
    "            return result\n",
    "        else:\n",
    "            return \"I'm sorry, but I'm unable to provide results. Could you please clarify your query so I can assist you better?\"\n",
    "        \n",
    "        conn.close()\n",
    "    \n",
    "    else:\n",
    "        # For non-database related queries, respond using the chatbot\n",
    "        return get_answer_from_chatbot(user_input, processed_schema_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84470d-0191-407e-8aa0-6731fc6d3a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  give me the list of milestones which are delayed by 7 or more days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash\\AppData\\Local\\Temp\\ipykernel_4756\\2895782655.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT *\n",
      "FROM milestones\n",
      "WHERE (end_date - CURRENT_DATE) > 7;\n",
      "Row: [('MedGenome Inc. - Zoho Marketing Automation', 'Milestone Three-AMC', 'Uday Desai', datetime.date(2024, 7, 8), datetime.date(2025, 7, 7), 'Upcoming', 'zcr_749813000021513025', 'zcr_749813000021509027', datetime.date(2024, 5, 27), 365, 23, 'On Time', Decimal('0.00'), 342, 'Upcoming', Decimal('0.00'), 'Zoho Marketing Automation'), ('Aajeeth Innovation LLP - Zoho CRM Implementation', 'Milestone Three-AMC', 'Uday Desai', datetime.date(2024, 8, 10), datetime.date(2025, 8, 9), 'Upcoming', 'zcr_749813000022031001', 'zcr_749813000022027005', datetime.date(2024, 7, 11), 365, -10, 'On Time', Decimal('0.00'), 375, 'Upcoming', Decimal('0.00'), 'CRM'), ('COLUMBIA PACIFIC COMMUNITIES - Zoho Books, Zoho Creator & Zoho Analytics', 'Milestone Five-Annual maintenance charges - Post Go-Live Application support for Zoho Books, Z', 'Uday Desai', datetime.date(2024, 7, 22), datetime.date(2025, 6, 20), 'Upcoming', 'zcr_749813000021877165', 'zcr_749813000021868194', datetime.date(2024, 6, 26), 334, 9, 'On Time', Decimal('0.00'), 325, 'Upcoming', Decimal('0.00'), 'NULL'), ('RERA Consultants LLP - Zoho CRM, Books, People, Collabrative Apps, Sign, Contracts', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho CRM, Zoho', 'Mohammed Yusha', datetime.date(2024, 5, 27), datetime.date(2025, 5, 26), 'Upcoming', 'zcr_749813000020687064', 'zcr_749813000020690063', datetime.date(2024, 3, 13), 365, 65, 'On Time', Decimal('0.00'), 300, 'Upcoming', Decimal('0.00'), 'Zoho One'), ('Healthplix -AMC 2024-25', 'Milestone One-HealthPlix -AMC for 2024-2025', 'Uday Desai', datetime.date(2024, 5, 6), datetime.date(2025, 5, 5), 'Upcoming', 'zcr_749813000021358197', 'zcr_749813000021362173', datetime.date(2024, 5, 15), 365, 86, 'On Time', Decimal('0.00'), 279, 'Upcoming', Decimal('0.00'), 'NULL'), ('Prodevans - Zoho Projects', 'Milestone Three-AMC for Software support charges (Yearly Billing) - Zoho Projects (50 Hours)', 'Irshad Pasha', datetime.date(2024, 3, 15), datetime.date(2025, 3, 14), 'Upcoming', 'zcr_749813000020570043', 'zcr_749813000020572025', datetime.date(2024, 2, 29), 365, 138, 'On Time', Decimal('0.00'), 227, 'Upcoming', Decimal('0.00'), 'Zoho Projects'), ('IIFL Samasta_ AMC_Support Tickets', 'Milestone One-Support Service Requests for Zoho Applications', 'Uday Desai', datetime.date(2023, 12, 30), datetime.date(2024, 12, 29), 'Upcoming', 'zcr_749813000020118043', 'zcr_749813000020120029', datetime.date(2024, 1, 19), 366, 214, 'On Time', Decimal('0.00'), 152, 'Upcoming', Decimal('0.00'), 'Creator'), ('JSW - Zoho Creator | Dedicate Resource', 'Milestone Six-Payment for September 2024 of the Dedicated Resource', 'Uday Desai', datetime.date(2024, 10, 1), datetime.date(2024, 10, 31), 'Upcoming', 'zcr_749813000021361161', 'zcr_749813000021358159', datetime.date(2024, 5, 15), 31, -62, 'On Time', Decimal('0.00'), 93, 'Upcoming', Decimal('0.00'), 'Creator'), ('AMC - VAlign', 'DEFSPACE_AMC_Zoho Books_09-02-2024 to 08-02-2025', 'Rishikesh Gogha', datetime.date(2024, 2, 9), datetime.date(2025, 2, 8), 'Upcoming', 'zcr_749813000020587420', 'zcr_749813000009144135', datetime.date(2024, 3, 6), 366, 173, 'On Time', Decimal('0.00'), 193, 'Upcoming', Decimal('0.00'), 'AMC'), ('AMC - VAlign', 'FARM INDIA IMPEX | Books, Creator, People, Payroll & Analytics  | 8-12-23 to 7-12-24', 'Maninder Singh', datetime.date(2023, 12, 8), datetime.date(2024, 12, 7), 'Upcoming', 'zcr_749813000020136426', 'zcr_749813000009144135', datetime.date(2024, 1, 24), 366, 236, 'On Time', Decimal('0.00'), 130, 'Upcoming', Decimal('0.00'), 'AMC'), ('CEEW - Zoho ONE - ERP Implementation', 'Milestone Twelve-Post Go-Live Application Support - Zoho ONE', 'Stuti S. Kulshrestha', datetime.date(2024, 11, 1), datetime.date(2025, 10, 31), 'Upcoming', 'zcr_749813000020094023', 'zcr_749813000020090005', datetime.date(2024, 1, 16), 365, -93, 'On Time', Decimal('0.00'), 458, 'Upcoming', Decimal('100000.00'), 'Zoho One'), ('Health First Services - Zoho People', 'Milestone Three-AMC', 'Uday Desai', datetime.date(2024, 7, 1), datetime.date(2025, 6, 30), 'Upcoming', 'zcr_749813000021603023', 'zcr_749813000021604011', datetime.date(2024, 6, 3), 365, 30, 'On Time', Decimal('0.00'), 335, 'Upcoming', Decimal('0.00'), 'Zoho People'), ('Osborn - AMC  2024', 'Milestone Two-Osborn - AMC _US_EMEA', 'Imtiyaz Ahmad', datetime.date(2024, 11, 3), datetime.date(2025, 6, 2), 'Upcoming', 'zcr_749813000021605107', 'zcr_749813000021606090', datetime.date(2024, 6, 4), 212, -95, 'On Time', Decimal('0.00'), 307, 'Upcoming', Decimal('0.00'), 'NULL'), ('Thoucentric AMC - 2024-2025', 'Milestone One-Thoucentric - AMC to Manage Support Tickets', 'Uday Desai', datetime.date(2024, 5, 9), datetime.date(2025, 5, 8), 'Upcoming', 'zcr_749813000021359167', 'zcr_749813000021361143', datetime.date(2024, 5, 15), 365, 83, 'On Time', Decimal('0.00'), 282, 'Upcoming', Decimal('0.00'), 'NULL'), ('GOFIBO - Zoho Books AMC', 'Milestone One-AMC for Software application support â€“ Zoho Books (Yearly Billing)', 'Uday Desai', datetime.date(2024, 3, 22), datetime.date(2025, 3, 21), 'Upcoming', 'zcr_749813000020826060', 'zcr_749813000020828102', datetime.date(2024, 3, 22), 365, 131, 'On Time', Decimal('0.00'), 234, 'Upcoming', Decimal('0.00'), 'NULL'), ('Prodevans - Zoho CRM', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho CRM', 'Anusha V', datetime.date(2024, 2, 1), datetime.date(2025, 1, 31), 'Upcoming', 'zcr_749813000020093031', 'zcr_749813000020090053', datetime.date(2024, 1, 16), 366, 181, 'On Time', Decimal('0.00'), 185, 'Upcoming', Decimal('32500.00'), 'AMC'), ('Osborn - AMC  2024', 'Milestone One-Osborn - AMC _US_EMEA', 'Imtiyaz Ahmad', datetime.date(2024, 6, 3), datetime.date(2024, 11, 2), 'Upcoming', 'zcr_749813000021606108', 'zcr_749813000021606090', datetime.date(2024, 6, 4), 153, 58, 'On Time', Decimal('0.00'), 95, 'Upcoming', Decimal('0.00'), 'NULL'), ('AMC - VAlign', 'Gofibo AMC 06-03-2024 to 05-03-2025', 'Tanu Gupta', datetime.date(2024, 3, 12), datetime.date(2025, 3, 6), 'Upcoming', 'zcr_749813000020822508', 'zcr_749813000009144135', datetime.date(2024, 3, 22), 360, 141, 'On Time', Decimal('0.00'), 219, 'Upcoming', Decimal('0.00'), 'AMC'), ('AMC - VAlign', 'AMC Airowire Networks_Zoho CRM, Books, Projects, Expense &  Analytics _29-12-2023 to 28-12-2024', 'Waheeba Khan', datetime.date(2023, 12, 29), datetime.date(2024, 12, 28), 'Upcoming', 'zcr_749813000020397664', 'zcr_749813000009144135', datetime.date(2024, 2, 15), 366, 215, 'On Time', Decimal('0.00'), 151, 'Upcoming', Decimal('0.00'), 'AMC'), ('AMC - VAlign', 'Neelgund Developers LLP | Zoho People, Recruit & Payroll | 19-10-2023 | 18-10-2024', 'Irshad Pasha', datetime.date(2023, 10, 19), datetime.date(2024, 10, 18), 'Upcoming', 'zcr_749813000019141012', 'zcr_749813000009144135', datetime.date(2023, 10, 19), 366, 286, 'On Time', Decimal('0.00'), 80, 'Upcoming', Decimal('0.00'), 'AMC'), ('B Skilling - Zoho CRM Implementation', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho CRM(For ', 'Uday Desai', datetime.date(2024, 8, 1), datetime.date(2025, 7, 31), 'Upcoming', 'zcr_749813000021923031', 'zcr_749813000021923013', datetime.date(2024, 6, 27), 365, -1, 'On Time', Decimal('0.00'), 366, 'Upcoming', Decimal('0.00'), 'NULL'), ('ABC International Placement Services', 'Milestone Three-AMC for Zoho Recruit', 'Uday Desai', datetime.date(2024, 6, 17), datetime.date(2025, 6, 16), 'Upcoming', 'zcr_749813000021438059', 'zcr_749813000021434083', datetime.date(2024, 5, 20), 365, 44, 'On Time', Decimal('0.00'), 321, 'Upcoming', Decimal('0.00'), 'Zoho Recruit'), ('Lotuspay Solutions - Zoho Desk', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho Desk(For', 'Mahantesh', datetime.date(2024, 5, 20), datetime.date(2025, 5, 19), 'Upcoming', 'zcr_749813000021201042', 'zcr_749813000021195031', datetime.date(2024, 4, 29), 365, 72, 'On Time', Decimal('0.00'), 293, 'Upcoming', Decimal('0.00'), 'NULL'), ('FURNISHKA - Zoho Books AMC', 'Milestone One-AMC for Software application support â€“ Zoho Books(Yearly Billing)', 'Uday Desai', datetime.date(2024, 4, 8), datetime.date(2025, 4, 7), 'Upcoming', 'zcr_749813000021022081', 'zcr_749813000021022063', datetime.date(2024, 4, 10), 365, 114, 'On Time', Decimal('0.00'), 251, 'Upcoming', Decimal('0.00'), 'NULL'), ('Accorian - Zoho CRM', 'Milestone Four-Annual maintenance charges Application Support â€“ Zoho CRM', 'Uday Desai', datetime.date(2024, 3, 4), datetime.date(2025, 3, 3), 'Upcoming', 'zcr_749813000020032041', 'zcr_749813000020034035', datetime.date(2024, 1, 10), 365, 149, 'On Time', Decimal('0.00'), 216, 'Upcoming', Decimal('112000.00'), 'AMC'), ('Airowire - Zoho AMC', 'Milestone One-Annual maintenance charges â€“ Software Applications support for Zoho CRM, Zoho Bo', 'Uday Desai', datetime.date(2023, 12, 29), datetime.date(2024, 12, 27), 'Upcoming', 'zcr_749813000019859143', 'zcr_749813000019862129', datetime.date(2023, 12, 29), 365, 215, 'On Time', Decimal('0.00'), 150, 'Upcoming', Decimal('0.00'), 'NULL'), ('CEEW - Zoho ONE - ERP Implementation', 'Milestone Eleven-Implementation of Zoho Analytics - Reports & Dashboards for Phase 2', 'Achyuth T M', datetime.date(2024, 9, 27), datetime.date(2024, 10, 25), 'Upcoming', 'zcr_749813000020090043', 'zcr_749813000020090005', datetime.date(2024, 1, 16), 29, -58, 'On Time', Decimal('0.00'), 87, 'Upcoming', Decimal('80000.00'), 'Analytics'), ('AMC - VAlign', 'ICAD AMC Support Issue', 'Tanu Gupta', datetime.date(2023, 8, 29), datetime.date(2024, 12, 31), 'Upcoming', 'zcr_749813000018705522', 'zcr_749813000009144135', datetime.date(2023, 8, 29), 491, 337, 'On Time', Decimal('0.00'), 154, 'Upcoming', Decimal('0.00'), 'AMC'), ('AMC - VAlign', 'Machani_AMC_Books_27-11-2023 to 26-11-2024', 'Waheeba Khan', datetime.date(2023, 11, 27), datetime.date(2024, 11, 26), 'Upcoming', 'zcr_749813000020340309', 'zcr_749813000009144135', datetime.date(2024, 2, 9), 366, 247, 'On Time', Decimal('0.00'), 119, 'Upcoming', Decimal('0.00'), 'AMC'), ('AMC - VAlign', 'Infifresh 01-01-2024 to 31-12-2024', 'Mohammed Yusha', datetime.date(2024, 1, 2), datetime.date(2024, 12, 31), 'Upcoming', 'zcr_749813000019889047', 'zcr_749813000009144135', datetime.date(2024, 1, 2), 365, 211, 'On Time', Decimal('0.00'), 154, 'Upcoming', Decimal('0.00'), 'AMC'), ('Ozone Entertainment - Zoho ONE', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho One Appl', 'Tanu Gupta', datetime.date(2024, 6, 3), datetime.date(2025, 6, 2), 'Upcoming', 'zcr_749813000019556053', 'zcr_749813000019556037', datetime.date(2023, 11, 29), 365, 58, 'On Time', Decimal('0.00'), 307, 'Upcoming', Decimal('0.00'), 'Zoho One'), ('VESTIAN MEA - Zoho CRM Implementation', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho CRM(For', 'Uday Desai', datetime.date(2024, 5, 9), datetime.date(2025, 5, 8), 'Upcoming', 'zcr_749813000021139221', 'zcr_749813000021136174', datetime.date(2024, 4, 23), 365, 83, 'On Time', Decimal('0.00'), 282, 'Upcoming', Decimal('0.00'), 'AMC'), ('Juspay - Zoho Desk & Zoho SalesIQ - PA', 'Milestone Three-Annual maintenance charges - Post Go-Live Application support for Zoho Desk & Zo', 'Mohammed Yusha', datetime.date(2024, 4, 1), datetime.date(2025, 3, 31), 'Upcoming', 'zcr_749813000020687021', 'zcr_749813000020686013', datetime.date(2024, 3, 12), 365, 121, 'On Time', Decimal('0.00'), 244, 'Upcoming', Decimal('0.00'), 'AMC'), ('FARM India AMC', 'Milestone One-Annual Maintenance Contract for  Zoho Software â€“ Zoho Books, Zoho Creator, Zoho ', 'Uday Desai', datetime.date(2023, 12, 8), datetime.date(2024, 12, 8), 'Upcoming', 'zcr_749813000019724011', 'zcr_749813000019720027', datetime.date(2023, 12, 12), 367, 236, 'On Time', Decimal('0.00'), 131, 'Upcoming', Decimal('0.00'), 'NULL'), ('BBS Global Pvt Ltd', 'Milestone Two-Implementation of a. Zoho CRM â€“ Enquiry & Sales Management Applicationb. Zoho', 'Tanu Gupta', datetime.date(2024, 4, 26), datetime.date(2025, 2, 24), 'Upcoming', 'zcr_749813000021139370', 'zcr_749813000021140317', datetime.date(2024, 4, 25), 305, 96, 'On Time', Decimal('0.00'), 209, 'Upcoming', Decimal('0.00'), 'NULL'), ('AMC - VAlign', 'HESPL AMC - 2023 - 24', 'Irshad Pasha', datetime.date(2023, 11, 16), datetime.date(2024, 11, 15), 'Upcoming', 'zcr_749813000019365420', 'zcr_749813000009144135', datetime.date(2023, 11, 17), 366, 258, 'On Time', Decimal('0.00'), 108, 'Upcoming', Decimal('123120.00'), 'AMC')]\n",
      "Here is a list of milestones that are delayed by 7 or more days:\n",
      "\n",
      "1. **MedGenome Inc. - Zoho Marketing Automation**\n",
      "   - Milestone: Milestone Three-AMC\n",
      "   - Responsible: Uday Desai\n",
      "   - Start Date: July 8, 2024\n",
      "   - End Date: July 7, 2025\n",
      "   - Status: Upcoming\n",
      "   - Delay: 23 days\n",
      "\n",
      "2. **Aajeeth Innovation LLP - Zoho CRM Implementation**\n",
      "   - Milestone: Milestone Three-AMC\n",
      "   - Responsible: Uday Desai\n",
      "   - Start Date: August 10, 2024\n",
      "   - End Date: August 9, 2025\n",
      "   - Status: Upcoming\n",
      "   - Delay: 10 days\n",
      "\n",
      "3. **Osborn - AMC 2024**\n",
      "   - Milestone: Milestone Two-Osborn - AMC _US_EMEA\n",
      "   - Responsible: Imtiyaz Ahmad\n",
      "   - Start Date: November 3, 2024\n",
      "   - End Date: June 2, 2025\n",
      "   - Status: Upcoming\n",
      "   - Delay: 95 days\n",
      "\n",
      "4. **CEEW - Zoho ONE - ERP Implementation**\n",
      "   - Milestone: Milestone Eleven-Implementation of Zoho Analytics - Reports & Dashboards for Phase 2\n",
      "   - Responsible: Achyuth T M\n",
      "   - Start Date: September 27, 2024\n",
      "   - End Date: October 25, 2024\n",
      "   - Status: Upcoming\n",
      "   - Delay: 58 days\n",
      "\n",
      "5. **GOFIBO - Zoho Books AMC**\n",
      "   - Milestone: Milestone One-AMC for Software application support – Zoho Books (Yearly Billing)\n",
      "   - Responsible: Uday Desai\n",
      "   - Start Date: March 22, 2024\n",
      "   - End Date: March 21, 2025\n",
      "   - Status: Upcoming\n",
      "   - Delay: 131 days\n",
      "\n",
      "These milestones are significantly delayed, indicating potential issues in project timelines.\n",
      "Here's an optimized SQL query to achieve that\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  give me the list of count of milestones which are delayed by 7 or more days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash\\AppData\\Local\\Temp\\ipykernel_4756\\2895782655.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT COUNT(*) AS delayed_milestone_count\n",
      "FROM milestones\n",
      "WHERE (CURRENT_DATE - end_date) >= 7;\n",
      "Row: [(1155,)]\n",
      "There are 1,155 milestones that are delayed by 7 or more days.\n",
      "To generate the SQL query that counts the number of milestones which are delayed by 7 or more days, we will need to\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input(\"Enter your question: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            break\n",
    "        response = process_user_query(user_input)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03532f26-3f9a-4f8c-9255-68522d7ea908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching entities found in user input.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733a7b5-23c6-47bd-b0b8-0860553c6ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
