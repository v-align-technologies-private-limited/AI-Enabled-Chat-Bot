{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aca26c7-5bec-4325-b1d0-85023c48ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22616\\510500084.py:72: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your query:  give me  the list tasks related to project IIFL Samasta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple matches found for 'IIFL Samasta':\n",
      "1: IIFl Samasta CPL CR\n",
      "2: IIFL Samasta - CGRM\n",
      "3: IIFL SAMASTA - RPA BOT\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select the most relevant option for 'IIFL Samasta' (1-3):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: ## Expected Output\n",
      "    SELECT *\n",
      "    FROM tasks\n",
      "    WHERE project_name LIKE '%IIFL SAMASTA - RPA BOT%';\n",
      "Error executing SQL query: syntax error at or near \"##\"\n",
      "LINE 1: ## Expected Output\n",
      "        ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pinecone\n",
    "import openai\n",
    "import os\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import uuid  # For generating unique session IDs\n",
    "\n",
    "# OpenAI API key\n",
    "OPENAI_API_KEY = ''\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Database connection details\n",
    "DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "DATABASE_USERNAME = \"postgres\"\n",
    "DATABASE_PASSWORD = \"valign#123\"\n",
    "DATABASE_DB = \"python_test_poc\"\n",
    "PORT = 5432\n",
    "\n",
    "# Constants\n",
    "PINECONE_API_KEY = \"9fbe58e4-9e72-4023-90eb-ba8d022916b5\"  # Replace with your Pinecone API key\n",
    "INDEX_NAME = \"smart-desk\"  # Replace with your Pinecone index name\n",
    "NAMESPACE = \"projects\"  # Replace with your namespace\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "# Initialize Pinecone client\n",
    "def initialize_pinecone():\n",
    "    from pinecone import Pinecone, ServerlessSpec\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    if INDEX_NAME not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=768,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    "        )\n",
    "    return pc.Index(INDEX_NAME)\n",
    "\n",
    "# Load Hugging Face model for embeddings\n",
    "def load_huggingface_model():\n",
    "    return SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DATABASE_DB,\n",
    "            user=DATABASE_USERNAME,\n",
    "            password=DATABASE_PASSWORD,\n",
    "            host=DATABASE_HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        raise\n",
    "        \n",
    "# Function to fetch schema from PostgreSQL database\n",
    "def fetch_schema(conn):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "        \"\"\"\n",
    "        schema_df = pd.read_sql(query, conn)\n",
    "        return schema_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching schema: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to process schema: remove special characters and convert to lowercase\n",
    "def process_schema(schema_df):\n",
    "    def clean_column_name(name):\n",
    "        return re.sub(r'[^a-zA-Z]', '', name).lower()\n",
    "\n",
    "    schema_df['processed_column_name'] = schema_df['column_name'].apply(clean_column_name)\n",
    "    return schema_df\n",
    "\n",
    "# Extract relevant entities based on regex and column names\n",
    "def extract_entities(user_query, schema):\n",
    "    entities = {\n",
    "        'project_name': None,\n",
    "        'owner': None\n",
    "    }\n",
    "    project_pattern = re.compile(r'project\\s+([a-zA-Z0-9_ ]+)', re.IGNORECASE)\n",
    "    owner_pattern = re.compile(r'owner\\s+of\\s+project\\s+([a-zA-Z0-9_ ]+)', re.IGNORECASE)\n",
    "    project_match = project_pattern.search(user_query)\n",
    "    if project_match:\n",
    "        entities['project_name'] = project_match.group(1).strip()\n",
    "    owner_match = owner_pattern.search(user_query)\n",
    "    if owner_match:\n",
    "        entities['owner'] = owner_match.group(1).strip()\n",
    "    return entities\n",
    "\n",
    "# Query Pinecone for relevant context and augment the input\n",
    "def query_pinecone_and_augment_input(user_input, entities, namespace):\n",
    "    embedding_model = load_huggingface_model()\n",
    "    pinecone_index = initialize_pinecone()\n",
    "    augmented_input = user_input\n",
    "    pinecone_data = {}\n",
    "    for entity_name, entity_value in entities.items():\n",
    "        if entity_value:\n",
    "            query_embedding = embedding_model.encode([entity_value])[0]\n",
    "            query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "            try:\n",
    "                result = pinecone_index.query(\n",
    "                    namespace=namespace,\n",
    "                    vector=query_embedding.tolist(),\n",
    "                    top_k=3,\n",
    "                    include_values=True,\n",
    "                    include_metadata=True\n",
    "                )\n",
    "                matches = result.get('matches', [])\n",
    "                if matches:\n",
    "                    unique_values = [match['metadata'].get('unique_value') for match in matches if 'metadata' in match]\n",
    "                    if unique_values:\n",
    "                        pinecone_data[entity_name] = unique_values\n",
    "                        if len(unique_values) > 1:\n",
    "                            print(f\"Multiple matches found for '{entity_value}':\")\n",
    "                            for idx, unique_value in enumerate(unique_values):\n",
    "                                print(f\"{idx + 1}: {unique_value}\")\n",
    "                            while True:\n",
    "                                selection = input(f\"Please select the most relevant option for '{entity_value}' (1-{len(unique_values)}): \")\n",
    "                                try:\n",
    "                                    selected_value = unique_values[int(selection) - 1]\n",
    "                                    augmented_input = augmented_input.replace(entity_value, selected_value)\n",
    "                                    break\n",
    "                                except (IndexError, ValueError):\n",
    "                                    print(\"Invalid selection. Please choose a valid option.\")\n",
    "                        else:\n",
    "                            augmented_input = augmented_input.replace(entity_value, unique_values[0])\n",
    "                else:\n",
    "                    print(f\"No matches found for {entity_value} in Pinecone.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error querying Pinecone: {str(e)}\")\n",
    "                return f\"Error querying Pinecone: {str(e)}\", {}\n",
    "    return augmented_input, pinecone_data\n",
    "\n",
    "def generate_sql_query(user_input, processed_schema_df):\n",
    "    schema_json = processed_schema_df.to_json(orient='records')\n",
    "    schema_with_types = processed_schema_df[['table_name', 'column_name']].to_dict(orient='records')  # Removed 'data_type'\n",
    "    \n",
    "    context = f\"\"\"\n",
    "    ## Database Schema Context\n",
    "    Schema JSON: {schema_json}\n",
    "    Detailed Schema: {schema_with_types}\n",
    "\n",
    "    ## User Input\n",
    "    Given the following user input: '{user_input}', generate an SQL query.\n",
    "    Use the LIKE operator for partial matches where appropriate. Handle data type mismatches explicitly.\n",
    "\n",
    "    ## Instructions\n",
    "    Based on the user input and the provided schema, generate an accurate SQL query.\n",
    "    Ensure the query maps correctly to the tables and columns in the database.\n",
    "    Handle data type casting if necessary to match columns with different types.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=context,\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        generated_query = response.choices[0].text.strip()\n",
    "        if generated_query.lower().startswith(\"the generated sql query is:\"):\n",
    "            generated_query = generated_query[len(\"The generated SQL query is:\"):].strip()\n",
    "        return generated_query\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error generating SQL query: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Initialize OpenAI Chat model\n",
    "openai_model = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "# Create a ChatPromptTemplate with the knowledge base included\n",
    "template = \"\"\"\n",
    "## Knowledge Base:\n",
    "{knowledge_base}\n",
    "\n",
    "## Database Schema:\n",
    "{database_schema}\n",
    "\n",
    "## Question:\n",
    "{question}\n",
    "\n",
    "## Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Statefully manage chat history\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "def generate_session_id():\n",
    "    \"\"\"Generate a unique session ID using UUID.\"\"\"\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "session_id = generate_session_id()\n",
    "\n",
    "chain = prompt_template | openai_model\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "def get_answer_from_chatbot(question, database_schema):\n",
    "    try:\n",
    "        prompt = prompt_template.format(\n",
    "            knowledge_base=\"\",\n",
    "            database_schema=database_schema,\n",
    "            question=question\n",
    "        )\n",
    "        response = openai_model.invoke(input=prompt)\n",
    "        parsed_response = response.content.strip() if hasattr(response, 'content') else \"No response content found.\"\n",
    "        return parsed_response\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response from OpenAI: {str(e)}\"\n",
    "\n",
    "# Function to execute the SQL query and print the results\n",
    "def execute_sql_query(conn, sql_query):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "            results = cursor.fetchall()\n",
    "            return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Determine if user query is related to database or general knowledge\n",
    "def determine_query_type(user_query, schema_df):\n",
    "    user_query_lower = user_query.lower()\n",
    "    \n",
    "    if any(table.lower() in user_query_lower for table in schema_df['table_name'].unique()) or \\\n",
    "       any(column.lower() in user_query_lower for column in schema_df['column_name'].unique()):\n",
    "        return \"database\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "def main():\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db()\n",
    "    schema_df = fetch_schema(conn)\n",
    "    processed_schema_df = process_schema(schema_df)\n",
    "\n",
    "    user_query = input(\"Please enter your query: \")\n",
    "\n",
    "    # Extract entities from the user query\n",
    "    entities = extract_entities(user_query, processed_schema_df)\n",
    "\n",
    "    # Determine if the query is related to the database or general knowledge\n",
    "    query_type = determine_query_type(user_query, processed_schema_df)\n",
    "\n",
    "    if query_type == \"database\":\n",
    "        # Query Pinecone and augment input\n",
    "        augmented_query, pinecone_data = query_pinecone_and_augment_input(user_query, entities, NAMESPACE)\n",
    "\n",
    "        # Generate SQL query\n",
    "        sql_query = generate_sql_query(augmented_query, processed_schema_df)\n",
    "        \n",
    "        print(f\"Generated SQL Query: {sql_query}\")\n",
    "\n",
    "        # Execute SQL query and print results\n",
    "        results = execute_sql_query(conn, sql_query)\n",
    "        if results:\n",
    "            for row in results:\n",
    "                print(row)\n",
    "    else:\n",
    "        # Use OpenAI for general knowledge questions\n",
    "        answer = get_answer_from_chatbot(user_query, processed_schema_df.to_json())\n",
    "        print(f\"Chatbot Answer: {answer}\")\n",
    "\n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b307a-0c81-4730-8b28-56c71d6ea0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import re\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# import openai\n",
    "# from fuzzywuzzy import fuzz\n",
    "\n",
    "# # OpenAI API key\n",
    "# OPENAI_API_KEY = 'sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S'\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# # PostgreSQL database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     \"\"\"Connect to the PostgreSQL database.\"\"\"\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Fetch schema with column names and data types\n",
    "# def fetch_schema_with_data_types(conn):\n",
    "#     \"\"\"Fetch the database schema with data types.\"\"\"\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name, data_type\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema with data types: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Format schema as a string for the prompt\n",
    "# def format_schema(schema_df):\n",
    "#     \"\"\"Format the schema DataFrame as a string.\"\"\"\n",
    "#     if schema_df is None or schema_df.empty:\n",
    "#         return \"No schema information available.\"\n",
    "    \n",
    "#     schema_str = \"\"\n",
    "#     grouped = schema_df.groupby('table_name')\n",
    "#     for table_name, group in grouped:\n",
    "#         columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "#         schema_str += f\"{table_name}: {columns}\\n\"\n",
    "#     return schema_str\n",
    "\n",
    "# # Function to generate SQL query using OpenAI\n",
    "# def generate_sql_query(schema_str, user_input, chat_history):\n",
    "#     \"\"\"Generate an SQL query using OpenAI based on the schema and user input.\"\"\"\n",
    "#     # Include chat history in the prompt\n",
    "#     chat_context = \"\\n\".join(chat_history)\n",
    "    \n",
    "#     prompt = f\"\"\"\n",
    "#     The database contains the following schema:\n",
    "#     {schema_str}\n",
    "    \n",
    "#     Previous interactions:\n",
    "#     {chat_context}\n",
    "    \n",
    "#     Based on this schema and the user request:\n",
    "#     \"{user_input}\"\n",
    "\n",
    "#     Generate an optimized SQL query that meets the user's intent.\n",
    "#     The query should be efficient and use the correct table and column names.\n",
    "#     \"\"\"\n",
    "\n",
    "#     try:\n",
    "#         # Call OpenAI using chat completion API\n",
    "#         response = openai.chat.completions.create(\n",
    "#             model=\"gpt-4o-mini-2024-07-18\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries, ensuring the use of appropriate operators like LIKE or expressions in sql queries like '% %' for  matches if needed. Accurately map user input to the relevant tables and columns in the database based on the provided schema, using the LIKE operator for partial matches where necessary. Handle data type mismatches explicitly by casting to the appropriate type when required, ensuring correct query execution. Additionally, Manage variations in user input, such as case sensitivity or small spelling differences, using flexible matching techniques to generate precise and reliable SQL queries.\"},\n",
    "#                 {\"role\": \"user\", \"content\": prompt}\n",
    "#             ],\n",
    "#             max_tokens=500,\n",
    "#             temperature=0.7\n",
    "#         )\n",
    "\n",
    "#         # Extract SQL query from the response\n",
    "#         sql_response = response.choices[0].message.content.strip()\n",
    "#         return sql_response\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error generating SQL query: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Extract generated SQL Query\n",
    "# def extract_sql_query(response):\n",
    "#     \"\"\"Extract SQL query from the OpenAI response.\"\"\"\n",
    "#     if response:\n",
    "#         start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "#         end = response.find(\"```\", start)\n",
    "#         sql_query = response[start:end].strip()\n",
    "#         return sql_query\n",
    "#     return None\n",
    "\n",
    "# # Function to execute the SQL query and print the results\n",
    "# def execute_sql_query(conn, sql_query):\n",
    "#     \"\"\"Execute the SQL query and return the results.\"\"\"\n",
    "#     try:\n",
    "#         with conn.cursor() as cursor:\n",
    "#             cursor.execute(sql_query)\n",
    "#             results = cursor.fetchall()\n",
    "#             return results\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing SQL query: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Determine if user query is related to database or general knowledge\n",
    "# def determine_query_type(user_query, schema_df, threshold=75):\n",
    "#     \"\"\"Determine if the user query is related to the database or general knowledge.\"\"\"\n",
    "#     user_query_lower = user_query.lower()\n",
    "    \n",
    "#     # Extract unique table and column names from the schema and convert to lowercase\n",
    "#     table_names = schema_df['table_name'].str.lower().unique()\n",
    "#     column_names = schema_df['column_name'].str.lower().unique()\n",
    "    \n",
    "#     # Function to check fuzzy match\n",
    "#     def is_fuzzy_match(query, options, threshold):\n",
    "#         for option in options:\n",
    "#             if fuzz.partial_ratio(query, option) >= threshold:\n",
    "#                 return True\n",
    "#         return False\n",
    "    \n",
    "#     # Check if user query matches any table or column name\n",
    "#     if is_fuzzy_match(user_query_lower, table_names, threshold) or \\\n",
    "#        is_fuzzy_match(user_query_lower, column_names, threshold):\n",
    "#         return \"database\"\n",
    "    \n",
    "#     return \"knowledge\"\n",
    "\n",
    "# # Main function to handle user queries\n",
    "# def process_user_query(user_input, chat_history):\n",
    "#     \"\"\"Process the user input and determine the appropriate response.\"\"\"\n",
    "#     conn = connect_to_db()\n",
    "#     if conn is None:\n",
    "#         print(\"Failed to connect to the database.\")\n",
    "#         return\n",
    "\n",
    "#     schema_df = fetch_schema_with_data_types(conn)\n",
    "#     if schema_df is None:\n",
    "#         print(\"Failed to fetch schema.\")\n",
    "#         return\n",
    "\n",
    "#     processed_schema_str = format_schema(schema_df)\n",
    "#     query_type = determine_query_type(user_input, schema_df)\n",
    "\n",
    "#     if query_type == \"database\":\n",
    "#         sql_query = generate_sql_query(processed_schema_str, user_input, chat_history)\n",
    "#         sql_query = extract_sql_query(sql_query)\n",
    "#         if sql_query:\n",
    "#             print(\"Generated SQL Query:\", sql_query)\n",
    "            \n",
    "#             # Execute the generated SQL query\n",
    "#             results = execute_sql_query(conn, sql_query)\n",
    "            \n",
    "#             if results:\n",
    "#                 print(\"Query Results:\", results)\n",
    "#                 chat_history.append(f\"User: {user_input}\\nSQL Query: {sql_query}\\nResults: {results}\")\n",
    "#             else:\n",
    "#                 print(\"No results returned for the SQL query.\")\n",
    "#         else:\n",
    "#             print(\"SQL query generation failed.\")\n",
    "        \n",
    "#     else:\n",
    "#         print(\"This query is not related to the database.\")\n",
    "\n",
    "#     conn.close()\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     chat_history = []\n",
    "#     while True:\n",
    "#         user_input = input(\"Enter your query (type 'exit' to quit): \")\n",
    "#         if user_input.lower() in ['exit', 'quit']:\n",
    "#             break\n",
    "#         process_user_query(user_input, chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d781a-dce9-4683-813b-4a97dfcd7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# import os\n",
    "# import json\n",
    "# from fuzzywuzzy import fuzz\n",
    "# import re\n",
    "\n",
    "\n",
    "# # Database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # OpenAI API key initialization\n",
    "# openai.api_key = 'sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S'\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Fetch schema with column names and data types\n",
    "# def fetch_schema_with_data_types(conn):\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name, data_type\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema with data types: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Format schema as a string for the prompt\n",
    "# def format_schema(schema_df):\n",
    "#     schema_str = \"\"\n",
    "#     grouped = schema_df.groupby('table_name')\n",
    "#     for table_name, group in grouped:\n",
    "#         columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "#         schema_str += f\"{table_name}: {columns}\\n\"\n",
    "#     return schema_str\n",
    "\n",
    "# # Function to generate SQL query using GPT-4o-mini\n",
    "# def generate_sql_query(schema_str, user_input):\n",
    "#     prompt = f\"\"\"\n",
    "#     The database contains the following schema:\n",
    "#     {schema_str}\n",
    "\n",
    "#     Based on this schema and the user request:\n",
    "#     \"{user_input}\"\n",
    "\n",
    "#     Generate an optimized SQL query that meets the user's intent.\n",
    "#     The query should be efficient and use the correct table and column names.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Call GPT-4o-mini-2024-07-18 model using chat completion API\n",
    "#     response = openai.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini-2024-07-18\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries, always ensuring the use of appropriate operators like LIKE or expressions in sql queries like '% %' for partial matches if needed. Accurately map user input to the relevant tables and columns in the database based on the provided schema, using the LIKE operator for partial matches where necessary. Handle data type mismatches explicitly by casting to the appropriate type when required, ensuring correct query execution. Additionally, Manage variations in user input, such as case sensitivity or small spelling differences, using flexible matching techniques to generate precise and reliable SQL queries.Note do not use ILIKE Operator\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         max_tokens=500,  # Reduced token limit for completion\n",
    "#         temperature=0.7\n",
    "#     )\n",
    "\n",
    "#     # Extract SQL query from the response\n",
    "#     sql_response = response.choices[0].message.content\n",
    "#     # Find and clean the SQL query part\n",
    "#     start = sql_response.find(\"```sql\") + 6\n",
    "#     end = sql_response.find(\"```\", start)\n",
    "#     sql_query = sql_response\n",
    "#     print(\"Response:\",sql_response)\n",
    "    \n",
    "\n",
    "#     return sql_query\n",
    "\n",
    "\n",
    "# # Initialize the chat history\n",
    "# chat_history = []\n",
    "\n",
    "# def chat_with_openai(user_message):\n",
    "#     # Append the user message to the chat history\n",
    "#     chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "#     # Prepare the messages to send to the OpenAI API\n",
    "#     messages = [{\"role\": message['role'], \"content\": message['content']} for message in chat_history]\n",
    "\n",
    "#     # Send the chat history to OpenAI\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",  # Use the desired model\n",
    "#         messages=messages,\n",
    "#         max_tokens=150,  # Adjust the max tokens as needed\n",
    "#         temperature=0.7  # Adjust the temperature for response variability\n",
    "#     )\n",
    "\n",
    "#     # Get the assistant's response\n",
    "#     assistant_response = response['choices'][0]['message']['content']\n",
    "\n",
    "#     # Append the assistant's response to the chat history\n",
    "#     chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "#     return assistant_response\n",
    "\n",
    "# # Example usage\n",
    "# user_input = \"What is the capital of France?\"\n",
    "# response = chat_with_openai(user_input)\n",
    "# print(\"Assistant:\", response)\n",
    "\n",
    "# # Continue the chat\n",
    "# follow_up_input = \"And what about Germany?\"\n",
    "# response = chat_with_openai(follow_up_input)\n",
    "# print(\"Assistant:\", response)\n",
    "\n",
    "\n",
    "# # Extract generated SQL Query\n",
    "# def extract_sql_query(response):\n",
    "#     start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "#     end = response.find(\"```\", start)\n",
    "#     sql_query = response[start:end].strip()\n",
    "#     return sql_query\n",
    "\n",
    "# # Initialize OpenAI Chat model\n",
    "# openai_model = ChatOpenAI(\n",
    "#     openai_api_key=openai.api_key,\n",
    "#     model_name=\"gpt-4o-mini-2024-07-18\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=150\n",
    "# )\n",
    "\n",
    "# #Generate Response\n",
    "# # Update the generate_response function\n",
    "# def generate_response(user_query, sql_result):\n",
    "#     # Prepare the prompt for GPT-4 to generate the natural language response\n",
    "#     prompt = f\"User query: \\\"{user_query}\\\"\\nSQL result: {sql_result}\\nGenerate a natural language response from the result:\"\n",
    "    \n",
    "#     # Call the OpenAI Chat API\n",
    "#     response = openai.chat.completions.create(\n",
    "#       model=\"gpt-4o-mini-2024-07-18\",\n",
    "#       messages=[\n",
    "#           {\"role\": \"user\", \"content\": prompt}\n",
    "#       ],\n",
    "#       max_tokens=500,\n",
    "#       temperature=0.7\n",
    "#     )\n",
    "    \n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "# # Make sure to replace the completion calls elsewhere in the code\n",
    "\n",
    "    \n",
    "# # Create a ChatPromptTemplate with the knowledge base included\n",
    "# template = \"\"\"\n",
    "# ## Knowledge Base:\n",
    "# {knowledge_base}\n",
    "\n",
    "# ## Database Schema:\n",
    "# {database_schema}\n",
    "\n",
    "# ## Question:\n",
    "# {question}\n",
    "\n",
    "# ## Answer:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# def get_answer_from_chatbot(question, database_schema):\n",
    "#     try:\n",
    "#         prompt = prompt_template.format(\n",
    "#             knowledge_base=\"\",\n",
    "#             database_schema=database_schema,\n",
    "#             question=question\n",
    "#         )\n",
    "#         response = openai_model.invoke(input=prompt)\n",
    "#         parsed_response = response.content.strip() if hasattr(response, 'content') else \"No response content found.\"\n",
    "#         return parsed_response\n",
    "#     except Exception as e:\n",
    "#         return f\"Error generating response from OpenAI: {str(e)}\"\n",
    "        \n",
    "# # Function to execute the SQL query and print the results\n",
    "# def execute_sql_query(conn, sql_query):\n",
    "#     try:\n",
    "#         with conn.cursor() as cursor:\n",
    "#             cursor.execute(sql_query)\n",
    "#             results = cursor.fetchall()\n",
    "#             print(results)\n",
    "#             return results\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing SQL query: {e}\")\n",
    "#         return None\n",
    "        \n",
    "# # Determine if user query is related to database or general knowledge\n",
    "# def determine_query_type(user_query, schema_df, threshold=75):\n",
    "#     user_query_lower = user_query.lower()\n",
    "    \n",
    "#     # Extract unique table and column names from the schema and convert to lowercase\n",
    "#     table_names = schema_df['table_name'].str.lower().unique()\n",
    "#     column_names = schema_df['column_name'].str.lower().unique()\n",
    "    \n",
    "#     # Function to check fuzzy match\n",
    "#     def is_fuzzy_match(query, options, threshold):\n",
    "#         for option in options:\n",
    "#             if fuzz.partial_ratio(query, option) >= threshold:\n",
    "#                 return True\n",
    "#         return False\n",
    "    \n",
    "#     # Check if user query matches any table or column name\n",
    "#     if is_fuzzy_match(user_query_lower, table_names, threshold) or \\\n",
    "#        is_fuzzy_match(user_query_lower, column_names, threshold):\n",
    "#         return \"database\"\n",
    "    \n",
    "#     return \"knowledge\"\n",
    "\n",
    "# # Main function to handle user queries\n",
    "# def process_user_query(user_input):\n",
    "#     conn = connect_to_db()\n",
    "#     schema_df = fetch_schema_with_data_types(conn)\n",
    "#     processed_schema_str = format_schema(schema_df)\n",
    "#     query_type = determine_query_type(user_input, schema_df)\n",
    "\n",
    "#     if query_type == \"database\":\n",
    "#         sql_query = generate_sql_query(processed_schema_str, user_input)\n",
    "#         sql_query=extract_sql_query(sql_query)\n",
    "        \n",
    "#         print(\"Generated SQL Query:\", sql_query)\n",
    "        \n",
    "#         # Execute the generated SQL query\n",
    "#         results = execute_sql_query(conn, sql_query)\n",
    "#         rows=results\n",
    "        \n",
    "#         print(\"Row:\",rows)\n",
    "#         if len(rows)!=0:\n",
    "#             print(generate_response(user_input,rows))\n",
    "#         else:\n",
    "#             print(\"I'm sorry, but I'm unable to provide results. Could you please clarify your query so I can assist you better?\")\n",
    "        \n",
    "#         conn.close()\n",
    "    \n",
    "#     else:\n",
    "#         # For non-database related queries, respond using the chatbot\n",
    "#         print(get_answer_from_chatbot(user_input, processed_schema_str))\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "#         user_input = input(\"Enter your query: \")\n",
    "#         if user_input.lower() in ['exit', 'quit']:\n",
    "#             break\n",
    "#         response = process_user_query(user_input)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad30ebb-2f9c-40c8-9972-733c3a7ff179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# import os\n",
    "# import json\n",
    "# from fuzzywuzzy import fuzz\n",
    "# import re\n",
    "\n",
    "# # Database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # OpenAI API key initialization\n",
    "# openai.api_key = 'sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S'\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Fetch schema with column names and data types\n",
    "# def fetch_schema_with_data_types(conn):\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name, data_type\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema with data types: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Format schema as a string for the prompt\n",
    "# def format_schema(schema_df):\n",
    "#     schema_str = \"\"\n",
    "#     grouped = schema_df.groupby('table_name')\n",
    "#     for table_name, group in grouped:\n",
    "#         columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "#         schema_str += f\"{table_name}: {columns}\\n\"\n",
    "#     return schema_str\n",
    "\n",
    "# # Function to generate SQL query using GPT-4o-mini\n",
    "# def generate_sql_query(schema_str, user_input):\n",
    "#     prompt = f\"\"\"\n",
    "#     The database contains the following schema:\n",
    "#     {schema_str}\n",
    "\n",
    "#     Based on this schema and the user request:\n",
    "#     \"{user_input}\"\n",
    "\n",
    "#     Generate an optimized SQL query that meets the user's intent.\n",
    "#     The query should be efficient and use the correct table and column names.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Call GPT-4o-mini-2024-07-18 model using chat completion API\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini-2024-07-18\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         max_tokens=500,  # Reduced token limit for completion\n",
    "#         temperature=0.7\n",
    "#     )\n",
    "\n",
    "#     # Extract SQL query from the response\n",
    "#     sql_response = response.choices[0].message.content\n",
    "    \n",
    "#     # # Find and clean the SQL query part\n",
    "#     # start = sql_response.find(\"```sql\") + 6\n",
    "#     # end = sql_response.find(\"```\", start)\n",
    "#     sql_query = sql_response\n",
    "    \n",
    "#     return sql_query\n",
    "\n",
    "# #extract generatedSQL Query\n",
    "# def extract_sql_query(response):\n",
    "#     # Find the start and end indices of the SQL code block\n",
    "#     start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "#     end = response.find(\"```\", start)\n",
    "    \n",
    "#     # Extract and clean the SQL query\n",
    "#     sql_query = response[start:end].strip()\n",
    "    \n",
    "#     return sql_query\n",
    "\n",
    "# # Initialize OpenAI Chat model\n",
    "# openai_model = ChatOpenAI(\n",
    "#     openai_api_key=OPENAI_API_KEY,\n",
    "#     model_name=\"gpt-3.5-turbo\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=150\n",
    "# )\n",
    "\n",
    "# # Create a ChatPromptTemplate with the knowledge base included\n",
    "# template = \"\"\"\n",
    "# ## Knowledge Base:\n",
    "# {knowledge_base}\n",
    "\n",
    "# ## Database Schema:\n",
    "# {database_schema}\n",
    "\n",
    "# ## Question:\n",
    "# {question}\n",
    "\n",
    "# ## Answer:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# def get_answer_from_chatbot(question, database_schema):\n",
    "#     try:\n",
    "#         prompt = prompt_template.format(\n",
    "#             knowledge_base=\"\",\n",
    "#             database_schema=database_schema,\n",
    "#             question=question\n",
    "#         )\n",
    "#         response = openai_model.invoke(input=prompt)\n",
    "#         parsed_response = response.content.strip() if hasattr(response, 'content') else \"No response content found.\"\n",
    "#         return parsed_response\n",
    "#     except Exception as e:\n",
    "#         return f\"Error generating response from OpenAI: {str(e)}\"\n",
    "        \n",
    "# # Function to execute the SQL query and print the results\n",
    "# def execute_sql_query(conn, sql_query):\n",
    "#     try:\n",
    "#         with conn.cursor() as cursor:\n",
    "#             cursor.execute(sql_query)\n",
    "#             results = cursor.fetchall()\n",
    "#             return results\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing SQL query: {e}\")\n",
    "#         return None\n",
    "        \n",
    "# # Determine if user query is related to database or general knowledge\n",
    "# def determine_query_type(user_input, schema_df, threshold = 75):\n",
    "#     user_query_lower = user_query.lower()\n",
    "    \n",
    "#     # Extract unique table and column names from the schema and convert to lowercase\n",
    "#     table_names = schema_df['table_name'].str.lower().unique()\n",
    "#     column_names = schema_df['column_name'].str.lower().unique()\n",
    "    \n",
    "#     # Function to check fuzzy match\n",
    "#     def is_fuzzy_match(query, options, threshold):\n",
    "#         for option in options:\n",
    "#             if fuzz.partial_ratio(query, option) >= threshold:\n",
    "#                 return True\n",
    "#         return False\n",
    "    \n",
    "#     # Check if user query matches any table or column name\n",
    "#     if is_fuzzy_match(user_query_lower, table_names, threshold) or \\\n",
    "#        is_fuzzy_match(user_query_lower, column_names, threshold):\n",
    "#         return \"database\"\n",
    "    \n",
    "#     return \"knowledge\"\n",
    "\n",
    "# # Main function to handle user queries\n",
    "# def process_user_query(user_input):\n",
    "#     # Connect to the database and fetch the schema\n",
    "#     conn = connect_to_db()\n",
    "#     schema_df = fetch_schema(conn)\n",
    "#     processed_schema_df = format_schema(schema_df)\n",
    "#     query_type = determine_query_type(user_input, schema_df)\n",
    "\n",
    "#     if query_type == \"database\":\n",
    "#         sql_query = generate_sql_from_input(user_query, processed_schema_df)\n",
    "        \n",
    "#         print(\"Generated SQL Query:\", sql_query)\n",
    "        \n",
    "#         # Execute the generated SQL query\n",
    "#         results = execute_sql_query(conn, sql_query)\n",
    "#         conn.close()\n",
    "\n",
    "#         if results is not None:\n",
    "#             print(\"Query Results:\")\n",
    "#             for row in results:\n",
    "#                 print(row)\n",
    "#         else:\n",
    "#             print(\"No results returned or error occurred during query execution.\")\n",
    "        \n",
    "#         return f\"Generated SQL Query: {sql_query}\"\n",
    "    \n",
    "#     else:\n",
    "#         # For non-database related queries, respond using the chatbot\n",
    "#         database_schema = fetch_schema_with_data_types(conn)  # Fetching schema again if needed\n",
    "#         database_schema_df = process_schema(database_schema)\n",
    "#         return get_answer_from_chatbot(user_input, database_schema_df.to_dict(orient='records'))\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "#         user_input = input(\"Enter your query: \")\n",
    "#         if user_input.lower() in ['exit', 'quit']:\n",
    "#             break\n",
    "#         response = process_user_query(user_input)\n",
    "#         print(response)\n",
    "\n",
    "\n",
    "# # # Example user input\n",
    "# # user_input = \"who is the most productive user\"\n",
    "\n",
    "# # # Fetch schema and generate SQL query\n",
    "# # conn = connect_to_db()\n",
    "# # schema_df = fetch_schema_with_data_types(conn)\n",
    "# # schema_str = format_schema(schema_df)\n",
    "# # sql_query = generate_sql_query(schema_str, user_input)\n",
    "# # sql_query=extract_sql_query(sql_query)\n",
    "# # results = execute_sql_query(conn, sql_query)\n",
    "# # print(sql_query)\n",
    "# # print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df1f6c-4294-47d2-bc42-3d74a9d4a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import psycopg2\n",
    "# import pandas as pd\n",
    "\n",
    "# # Database connection details\n",
    "# DATABASE_HOST = \"database-test-postgress-instance.cpk2uyae6iza.ap-south-1.rds.amazonaws.com\"\n",
    "# DATABASE_USERNAME = \"postgres\"\n",
    "# DATABASE_PASSWORD = \"valign#123\"\n",
    "# DATABASE_DB = \"python_test_poc\"\n",
    "# PORT = 5432\n",
    "\n",
    "# # OpenAI API key initialization\n",
    "# openai.api_key = 'sk-proj-UnzdWuWBs7ZQRbRPiRCoT3BlbkFJhPM1p7DdZUMklcpnWK1S'\n",
    "\n",
    "# # Function to connect to PostgreSQL database\n",
    "# def connect_to_db():\n",
    "#     try:\n",
    "#         conn = psycopg2.connect(\n",
    "#             dbname=DATABASE_DB,\n",
    "#             user=DATABASE_USERNAME,\n",
    "#             password=DATABASE_PASSWORD,\n",
    "#             host=DATABASE_HOST,\n",
    "#             port=PORT\n",
    "#         )\n",
    "#         return conn\n",
    "#     except psycopg2.Error as e:\n",
    "#         print(f\"Error connecting to the database: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Fetch schema with column names and data types\n",
    "# def fetch_schema_with_data_types(conn):\n",
    "#     try:\n",
    "#         query = \"\"\"\n",
    "#         SELECT table_name, column_name, data_type\n",
    "#         FROM information_schema.columns\n",
    "#         WHERE table_schema = 'public'\n",
    "#         \"\"\"\n",
    "#         schema_df = pd.read_sql(query, conn)\n",
    "#         return schema_df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching schema with data types: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Format schema as a string for the prompt\n",
    "# def format_schema(schema_df):\n",
    "#     schema_str = \"\"\n",
    "#     grouped = schema_df.groupby('table_name')\n",
    "#     for table_name, group in grouped:\n",
    "#         columns = ', '.join([f\"{row['column_name']} ({row['data_type']})\" for _, row in group.iterrows()])\n",
    "#         schema_str += f\"{table_name}: {columns}\\n\"\n",
    "#     return schema_str\n",
    "\n",
    "# # Function to generate SQL query using GPT-4o-mini\n",
    "# def generate_sql_query(schema_str, user_input):\n",
    "#     prompt = f\"\"\"\n",
    "#     The database contains the following schema:\n",
    "#     {schema_str}\n",
    "\n",
    "#     Based on this schema and the user request:\n",
    "#     \"{user_input}\"\n",
    "\n",
    "#     Generate an optimized SQL query that meets the user's intent.\n",
    "#     The query should be efficient and use the correct table and column names.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Call GPT-4o-mini-2024-07-18 model using chat completion API\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini-2024-07-18\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in generating SQL queries.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         max_tokens=500,  # Reduced token limit for completion\n",
    "#         temperature=0.7\n",
    "#     )\n",
    "\n",
    "#     # Extract SQL query from the response\n",
    "#     sql_response = response.choices[0].message.content\n",
    "    \n",
    "#     # # Find and clean the SQL query part\n",
    "#     # start = sql_response.find(\"```sql\") + 6\n",
    "#     # end = sql_response.find(\"```\", start)\n",
    "#     sql_query = sql_response\n",
    "    \n",
    "#     return sql_query\n",
    "\n",
    "# def extract_sql_query(response):\n",
    "#     # Find the start and end indices of the SQL code block\n",
    "#     start = response.find(\"```sql\") + len(\"```sql\\n\")\n",
    "#     end = response.find(\"```\", start)\n",
    "    \n",
    "#     # Extract and clean the SQL query\n",
    "#     sql_query = response[start:end].strip()\n",
    "    \n",
    "#     return sql_query\n",
    "    \n",
    "# # Example user input\n",
    "# user_input = \"which is the longest delayed or lagged milestone name\"\n",
    "\n",
    "# # Fetch schema and generate SQL query\n",
    "# conn = connect_to_db()\n",
    "# schema_df = fetch_schema_with_data_types(conn)\n",
    "# schema_str = format_schema(schema_df)\n",
    "# sql_query = generate_sql_query(schema_str, user_input)\n",
    "# sql_query=extract_sql_query(sql_query)\n",
    "# # Print the cleaned SQL query\n",
    "# print(\"Generated SQL Query:\")\n",
    "# print(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f924564-e9b3-4c53-b1d5-3ee930821ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
